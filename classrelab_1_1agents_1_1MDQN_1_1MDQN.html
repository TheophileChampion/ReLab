<!-- HTML header for doxygen 1.9.8-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.6"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>ReLab | Documentation</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ðŸš€</text></svg>">
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<script type="text/javascript" src="doxygen-awesome-darkmode-toggle.js"></script>
<script type="text/javascript">
    DoxygenAwesomeDarkModeToggle.init()
</script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="doxygen-awesome.css" rel="stylesheet" type="text/css"/>
<link href="custom.css" rel="stylesheet" type="text/css"/>
<link href="doxygen-awesome-sidebar-only.css" rel="stylesheet" type="text/css"/>
<link href="doxygen-awesome-sidebar-only-darkmode-toggle.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectlogo"><img alt="Logo" src="relab-logo-only.png"/></td>
  <td id="projectalign">
   <div id="projectname">ReLab<span id="projectnumber">&#160;v1.0.0-b</span>
   </div>
   <div id="projectbrief">Reinforcement Learning Benchmarks</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.6 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(document).ready(function(){initNavTree('classrelab_1_1agents_1_1MDQN_1_1MDQN.html',''); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div class="header">
  <div class="summary">
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="classrelab_1_1agents_1_1MDQN_1_1MDQN-members.html">List of all members</a>  </div>
  <div class="headertitle"><div class="title">relab.agents.MDQN.MDQN Class Reference</div></div>
</div><!--header-->
<div class="contents">

<p>Implements a multistep Deep Q-Network.  
 <a href="classrelab_1_1agents_1_1MDQN_1_1MDQN.html#details">More...</a></p>
<div class="dynheader">
Inheritance diagram for relab.agents.MDQN.MDQN:</div>
<div class="dyncontent">
<div class="center"><img src="classrelab_1_1agents_1_1MDQN_1_1MDQN__inherit__graph.png" border="0" usemap="#arelab_8agents_8MDQN_8MDQN_inherit__map" alt="Inheritance graph"/></div>
<map name="arelab_8agents_8MDQN_8MDQN_inherit__map" id="arelab_8agents_8MDQN_8MDQN_inherit__map">
<area shape="rect" title="Implements a multistep Deep Q&#45;Network." alt="" coords="11,240,206,265"/>
<area shape="rect" href="classrelab_1_1agents_1_1DQN_1_1DQN.html" title="Implements a Deep Q&#45;Network." alt="" coords="23,167,194,192"/>
<area shape="rect" href="classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface.html" title="The interface that all agents must implement." alt="" coords="5,79,212,119"/>
<area shape="rect" title=" " alt="" coords="84,5,133,31"/>
</map>
<center><span class="legend">[<a target="top" href="graph_legend.html">legend</a>]</span></center></div>
<div class="dynheader">
Collaboration diagram for relab.agents.MDQN.MDQN:</div>
<div class="dyncontent">
<div class="center"><img src="classrelab_1_1agents_1_1MDQN_1_1MDQN__coll__graph.png" border="0" usemap="#arelab_8agents_8MDQN_8MDQN_coll__map" alt="Collaboration graph"/></div>
<map name="arelab_8agents_8MDQN_8MDQN_coll__map" id="arelab_8agents_8MDQN_8MDQN_coll__map">
<area shape="rect" title="Implements a multistep Deep Q&#45;Network." alt="" coords="11,240,206,265"/>
<area shape="rect" href="classrelab_1_1agents_1_1DQN_1_1DQN.html" title="Implements a Deep Q&#45;Network." alt="" coords="23,167,194,192"/>
<area shape="rect" href="classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface.html" title="The interface that all agents must implement." alt="" coords="5,79,212,119"/>
<area shape="rect" title=" " alt="" coords="84,5,133,31"/>
</map>
<center><span class="legend">[<a target="top" href="graph_legend.html">legend</a>]</span></center></div>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pub-methods" name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:a8a4b112cc8177e91233bd1c5d090e008"><td class="memItemLeft" align="right" valign="top">None&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrelab_1_1agents_1_1MDQN_1_1MDQN.html#a8a4b112cc8177e91233bd1c5d090e008">__init__</a> (self, float <a class="el" href="classrelab_1_1agents_1_1DQN_1_1DQN.html#a2587135d7d9055a60ba69025563769ae">gamma</a>=0.99, float <a class="el" href="classrelab_1_1agents_1_1DQN_1_1DQN.html#afbdb81a773ff9c8974fcd3cb0ac6d25d">learning_rate</a>=0.00001, int <a class="el" href="classrelab_1_1agents_1_1DQN_1_1DQN.html#ad9e7a11caa27eca86e0460f84342c3f9">buffer_size</a>=1000000, int <a class="el" href="classrelab_1_1agents_1_1DQN_1_1DQN.html#ace1892c0e7a64acdb36c5cca15f944e0">batch_size</a>=32, int <a class="el" href="classrelab_1_1agents_1_1DQN_1_1DQN.html#ac24fbc141ab886ed3acc8231809dfa3a">learning_starts</a>=200000, int <a class="el" href="classrelab_1_1agents_1_1DQN_1_1DQN.html#aabd2a4bbb70d1ea02543593983318b9d">target_update_interval</a>=40000, float <a class="el" href="classrelab_1_1agents_1_1DQN_1_1DQN.html#a2d767c31ee310a484c1b532557421776">adam_eps</a>=1.5e-4, int <a class="el" href="classrelab_1_1agents_1_1DQN_1_1DQN.html#a3073c515322440f72bea0dc53858b16f">n_actions</a>=18, int <a class="el" href="classrelab_1_1agents_1_1DQN_1_1DQN.html#a5df9017e12bc717732e49b9e9f8ce255">n_atoms</a>=1, bool <a class="el" href="classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface.html#aebe9410ff0c783d702877cba754bdfe4">training</a>=True, int <a class="el" href="classrelab_1_1agents_1_1DQN_1_1DQN.html#aa1f80ea708eea38b8b46c9c96220abe6">n_steps</a>=3, <a class="el" href="classrelab_1_1agents_1_1AgentInterface_1_1ReplayType.html">ReplayType</a> <a class="el" href="classrelab_1_1agents_1_1DQN_1_1DQN.html#a8eaa62eca1d1b02b091befeaa854b4e8">replay_type</a>=<a class="el" href="classrelab_1_1agents_1_1AgentInterface_1_1ReplayType.html#a4f90b2efe6b7277c4f764b18770ba4e5">ReplayType.MULTISTEP</a>, <a class="el" href="classrelab_1_1agents_1_1DQN_1_1LossType.html">LossType</a> <a class="el" href="classrelab_1_1agents_1_1DQN_1_1DQN.html#aa09f06ba76e978d3571ede38ce61209e">loss_type</a>=<a class="el" href="classrelab_1_1agents_1_1DQN_1_1LossType.html#a7fc4dd09dd09f4cad7e8b2f80525794f">LossType.DQN_SL1</a>, <a class="el" href="classrelab_1_1agents_1_1DQN_1_1NetworkType.html">NetworkType</a> <a class="el" href="classrelab_1_1agents_1_1DQN_1_1DQN.html#ac0794239af64612da5c0ae9a1b68e18b">network_type</a>=<a class="el" href="classrelab_1_1agents_1_1DQN_1_1NetworkType.html#a151e691483dc02332cb23e2d3d9c88a8">NetworkType.DEFAULT</a>)</td></tr>
<tr class="memdesc:a8a4b112cc8177e91233bd1c5d090e008"><td class="mdescLeft">&#160;</td><td class="mdescRight">Create a DQN agent.  <br /></td></tr>
<tr class="separator:a8a4b112cc8177e91233bd1c5d090e008"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="inherit_header pub_methods_classrelab_1_1agents_1_1DQN_1_1DQN"><td colspan="2" onclick="javascript:toggleInherit('pub_methods_classrelab_1_1agents_1_1DQN_1_1DQN')"><img src="closed.png" alt="-"/>&#160;Public Member Functions inherited from <a class="el" href="classrelab_1_1agents_1_1DQN_1_1DQN.html">relab.agents.DQN.DQN</a></td></tr>
<tr class="memitem:a2d91aced72b5b4b01098fba9e85abaf3 inherit pub_methods_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="memItemLeft" align="right" valign="top">None&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrelab_1_1agents_1_1DQN_1_1DQN.html#a2d91aced72b5b4b01098fba9e85abaf3">__init__</a> (self, float <a class="el" href="classrelab_1_1agents_1_1DQN_1_1DQN.html#a2587135d7d9055a60ba69025563769ae">gamma</a>=0.99, float <a class="el" href="classrelab_1_1agents_1_1DQN_1_1DQN.html#afbdb81a773ff9c8974fcd3cb0ac6d25d">learning_rate</a>=0.00001, int <a class="el" href="classrelab_1_1agents_1_1DQN_1_1DQN.html#ad9e7a11caa27eca86e0460f84342c3f9">buffer_size</a>=1000000, int <a class="el" href="classrelab_1_1agents_1_1DQN_1_1DQN.html#ace1892c0e7a64acdb36c5cca15f944e0">batch_size</a>=32, int <a class="el" href="classrelab_1_1agents_1_1DQN_1_1DQN.html#ac24fbc141ab886ed3acc8231809dfa3a">learning_starts</a>=200000, Optional[float] <a class="el" href="classrelab_1_1agents_1_1DQN_1_1DQN.html#aaa183522b6ce8b71287e535597a6f04f">kappa</a>=None, int <a class="el" href="classrelab_1_1agents_1_1DQN_1_1DQN.html#aabd2a4bbb70d1ea02543593983318b9d">target_update_interval</a>=40000, float <a class="el" href="classrelab_1_1agents_1_1DQN_1_1DQN.html#a2d767c31ee310a484c1b532557421776">adam_eps</a>=1.5e-4, int <a class="el" href="classrelab_1_1agents_1_1DQN_1_1DQN.html#a3073c515322440f72bea0dc53858b16f">n_actions</a>=18, Optional[int] <a class="el" href="classrelab_1_1agents_1_1DQN_1_1DQN.html#a5df9017e12bc717732e49b9e9f8ce255">n_atoms</a>=None, Optional[float] <a class="el" href="classrelab_1_1agents_1_1DQN_1_1DQN.html#a8bc4145119334efced67f11d1fa11046">v_min</a>=None, Optional[float] <a class="el" href="classrelab_1_1agents_1_1DQN_1_1DQN.html#a1704a1876e59896f48375bb63e96a2ca">v_max</a>=None, int <a class="el" href="classrelab_1_1agents_1_1DQN_1_1DQN.html#aa1f80ea708eea38b8b46c9c96220abe6">n_steps</a>=1, bool <a class="el" href="classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface.html#aebe9410ff0c783d702877cba754bdfe4">training</a>=True, <a class="el" href="classrelab_1_1agents_1_1AgentInterface_1_1ReplayType.html">ReplayType</a> <a class="el" href="classrelab_1_1agents_1_1DQN_1_1DQN.html#a8eaa62eca1d1b02b091befeaa854b4e8">replay_type</a>=<a class="el" href="classrelab_1_1agents_1_1AgentInterface_1_1ReplayType.html#a84ebd587efe64396ce0fc381e39406e7">ReplayType.DEFAULT</a>, <a class="el" href="classrelab_1_1agents_1_1DQN_1_1LossType.html">LossType</a> <a class="el" href="classrelab_1_1agents_1_1DQN_1_1DQN.html#aa09f06ba76e978d3571ede38ce61209e">loss_type</a>=<a class="el" href="classrelab_1_1agents_1_1DQN_1_1LossType.html#a7fc4dd09dd09f4cad7e8b2f80525794f">LossType.DQN_SL1</a>, <a class="el" href="classrelab_1_1agents_1_1DQN_1_1NetworkType.html">NetworkType</a> <a class="el" href="classrelab_1_1agents_1_1DQN_1_1DQN.html#ac0794239af64612da5c0ae9a1b68e18b">network_type</a>=<a class="el" href="classrelab_1_1agents_1_1DQN_1_1NetworkType.html#a151e691483dc02332cb23e2d3d9c88a8">NetworkType.DEFAULT</a>, float <a class="el" href="classrelab_1_1agents_1_1DQN_1_1DQN.html#a892b68fea851e507f510667be9971056">omega</a>=1.0, float <a class="el" href="classrelab_1_1agents_1_1DQN_1_1DQN.html#ae5523e1136c036b6e1b54f40b7af0ea0">omega_is</a>=1.0, Any <a class="el" href="classrelab_1_1agents_1_1DQN_1_1DQN.html#a019621ab0c19444789434487859875f5">epsilon_schedule</a>=None)</td></tr>
<tr class="memdesc:a2d91aced72b5b4b01098fba9e85abaf3 inherit pub_methods_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="mdescLeft">&#160;</td><td class="mdescRight">Create a DQN agent.  <br /></td></tr>
<tr class="separator:a2d91aced72b5b4b01098fba9e85abaf3 inherit pub_methods_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa493fd9606ce72d1bad97b67f6f73110 inherit pub_methods_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="memItemLeft" align="right" valign="top">Callable&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrelab_1_1agents_1_1DQN_1_1DQN.html#aa493fd9606ce72d1bad97b67f6f73110">get_loss</a> (self, <a class="el" href="classrelab_1_1agents_1_1DQN_1_1LossType.html">LossType</a> <a class="el" href="classrelab_1_1agents_1_1DQN_1_1DQN.html#aa09f06ba76e978d3571ede38ce61209e">loss_type</a>)</td></tr>
<tr class="memdesc:aa493fd9606ce72d1bad97b67f6f73110 inherit pub_methods_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="mdescLeft">&#160;</td><td class="mdescRight">Retrieve the loss requested as parameters.  <br /></td></tr>
<tr class="separator:aa493fd9606ce72d1bad97b67f6f73110 inherit pub_methods_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5bcef6e093e941977ba2716ab7469df5 inherit pub_methods_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="memItemLeft" align="right" valign="top">nn.Module&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrelab_1_1agents_1_1DQN_1_1DQN.html#a5bcef6e093e941977ba2716ab7469df5">get_value_network</a> (self, <a class="el" href="classrelab_1_1agents_1_1DQN_1_1NetworkType.html">NetworkType</a> <a class="el" href="classrelab_1_1agents_1_1DQN_1_1DQN.html#ac0794239af64612da5c0ae9a1b68e18b">network_type</a>)</td></tr>
<tr class="memdesc:a5bcef6e093e941977ba2716ab7469df5 inherit pub_methods_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="mdescLeft">&#160;</td><td class="mdescRight">Retrieve the constructor of the value network requested as parameters.  <br /></td></tr>
<tr class="separator:a5bcef6e093e941977ba2716ab7469df5 inherit pub_methods_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6c0ef9bd6fccc1147fcc9c3b4adcdb0a inherit pub_methods_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="memItemLeft" align="right" valign="top"><a id="a6c0ef9bd6fccc1147fcc9c3b4adcdb0a" name="a6c0ef9bd6fccc1147fcc9c3b4adcdb0a"></a>
None&#160;</td><td class="memItemRight" valign="bottom"><b>update_target_network</b> (self)</td></tr>
<tr class="memdesc:a6c0ef9bd6fccc1147fcc9c3b4adcdb0a inherit pub_methods_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="mdescLeft">&#160;</td><td class="mdescRight">Synchronize the target with the value network. <br /></td></tr>
<tr class="separator:a6c0ef9bd6fccc1147fcc9c3b4adcdb0a inherit pub_methods_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a84fd3832544a0135720516681e4fff3b inherit pub_methods_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="memItemLeft" align="right" valign="top">ActionType&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrelab_1_1agents_1_1DQN_1_1DQN.html#a84fd3832544a0135720516681e4fff3b">step</a> (self, ObservationType obs)</td></tr>
<tr class="memdesc:a84fd3832544a0135720516681e4fff3b inherit pub_methods_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="mdescLeft">&#160;</td><td class="mdescRight">Select the next action to perform in the environment.  <br /></td></tr>
<tr class="separator:a84fd3832544a0135720516681e4fff3b inherit pub_methods_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afb3c1f57ed16d94b8cd82bf4ffe24276 inherit pub_methods_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="memItemLeft" align="right" valign="top">None&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrelab_1_1agents_1_1DQN_1_1DQN.html#afb3c1f57ed16d94b8cd82bf4ffe24276">train</a> (self, Env env)</td></tr>
<tr class="memdesc:afb3c1f57ed16d94b8cd82bf4ffe24276 inherit pub_methods_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="mdescLeft">&#160;</td><td class="mdescRight">Train the agent in the gym environment passed as parameters.  <br /></td></tr>
<tr class="separator:afb3c1f57ed16d94b8cd82bf4ffe24276 inherit pub_methods_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a95277e85d8860699b182dad545cc53d8 inherit pub_methods_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="memItemLeft" align="right" valign="top"><a id="a95277e85d8860699b182dad545cc53d8" name="a95277e85d8860699b182dad545cc53d8"></a>
Optional[Dict[str, Any]]&#160;</td><td class="memItemRight" valign="bottom"><b>learn</b> (self)</td></tr>
<tr class="memdesc:a95277e85d8860699b182dad545cc53d8 inherit pub_methods_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="mdescLeft">&#160;</td><td class="mdescRight">Perform one step of gradient descent on the value network. <br /></td></tr>
<tr class="separator:a95277e85d8860699b182dad545cc53d8 inherit pub_methods_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae48f88cd975789aa822759948024a52d inherit pub_methods_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="memItemLeft" align="right" valign="top">Tensor&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrelab_1_1agents_1_1DQN_1_1DQN.html#ae48f88cd975789aa822759948024a52d">q_learning_loss</a> (self, Tensor obs, Tensor actions, Tensor rewards, Tensor done, Tensor next_obs, Loss loss_fc, bool double_ql=False)</td></tr>
<tr class="memdesc:ae48f88cd975789aa822759948024a52d inherit pub_methods_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="mdescLeft">&#160;</td><td class="mdescRight">Compute the loss of the standard or double Q-learning algorithm.  <br /></td></tr>
<tr class="separator:ae48f88cd975789aa822759948024a52d inherit pub_methods_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1bb2e42715c44dbef27fc53214e46bdf inherit pub_methods_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="memItemLeft" align="right" valign="top">Tensor&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrelab_1_1agents_1_1DQN_1_1DQN.html#a1bb2e42715c44dbef27fc53214e46bdf">categorical_kl_divergence</a> (self, Tensor obs, Tensor actions, Tensor rewards, Tensor done, Tensor next_obs)</td></tr>
<tr class="memdesc:a1bb2e42715c44dbef27fc53214e46bdf inherit pub_methods_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="mdescLeft">&#160;</td><td class="mdescRight">Compute the loss of the categorical algorithm.  <br /></td></tr>
<tr class="separator:a1bb2e42715c44dbef27fc53214e46bdf inherit pub_methods_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6a59bd7deacfd2b50b3bddd6b1593b44 inherit pub_methods_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="memItemLeft" align="right" valign="top">Tensor&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrelab_1_1agents_1_1DQN_1_1DQN.html#a6a59bd7deacfd2b50b3bddd6b1593b44">rainbow_loss</a> (self, Tensor obs, Tensor actions, Tensor rewards, Tensor done, Tensor next_obs)</td></tr>
<tr class="memdesc:a6a59bd7deacfd2b50b3bddd6b1593b44 inherit pub_methods_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="mdescLeft">&#160;</td><td class="mdescRight">Compute the loss of the rainbow DQN.  <br /></td></tr>
<tr class="separator:a6a59bd7deacfd2b50b3bddd6b1593b44 inherit pub_methods_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad23433148a895775990e6dc59622fd73 inherit pub_methods_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="memItemLeft" align="right" valign="top">Tensor&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrelab_1_1agents_1_1DQN_1_1DQN.html#ad23433148a895775990e6dc59622fd73">quantile_loss</a> (self, Tensor obs, Tensor actions, Tensor rewards, Tensor done, Tensor next_obs, float <a class="el" href="classrelab_1_1agents_1_1DQN_1_1DQN.html#aaa183522b6ce8b71287e535597a6f04f">kappa</a>=1.0)</td></tr>
<tr class="memdesc:ad23433148a895775990e6dc59622fd73 inherit pub_methods_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="mdescLeft">&#160;</td><td class="mdescRight">Compute the loss of the quantile regression algorithm.  <br /></td></tr>
<tr class="separator:ad23433148a895775990e6dc59622fd73 inherit pub_methods_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1342607ce111ebf505f15cd68d5cdeeb inherit pub_methods_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="memItemLeft" align="right" valign="top">Tensor&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrelab_1_1agents_1_1DQN_1_1DQN.html#a1342607ce111ebf505f15cd68d5cdeeb">implicit_quantile_loss</a> (self, Tensor obs, Tensor actions, Tensor rewards, Tensor done, Tensor next_obs, float <a class="el" href="classrelab_1_1agents_1_1DQN_1_1DQN.html#aaa183522b6ce8b71287e535597a6f04f">kappa</a>=1.0)</td></tr>
<tr class="memdesc:a1342607ce111ebf505f15cd68d5cdeeb inherit pub_methods_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="mdescLeft">&#160;</td><td class="mdescRight">Compute the loss of the quantile regression algorithm.  <br /></td></tr>
<tr class="separator:a1342607ce111ebf505f15cd68d5cdeeb inherit pub_methods_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6e8746bfe529654d438c361485e32291 inherit pub_methods_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="memItemLeft" align="right" valign="top">Tensor&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrelab_1_1agents_1_1DQN_1_1DQN.html#a6e8746bfe529654d438c361485e32291">rainbow_iqn_loss</a> (self, Tensor obs, Tensor actions, Tensor rewards, Tensor done, Tensor next_obs, float <a class="el" href="classrelab_1_1agents_1_1DQN_1_1DQN.html#aaa183522b6ce8b71287e535597a6f04f">kappa</a>=1.0)</td></tr>
<tr class="memdesc:a6e8746bfe529654d438c361485e32291 inherit pub_methods_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="mdescLeft">&#160;</td><td class="mdescRight">Compute the loss of the rainbow IQN.  <br /></td></tr>
<tr class="separator:a6e8746bfe529654d438c361485e32291 inherit pub_methods_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab5eba6790ccbd1d07171f0c2a5df2f93 inherit pub_methods_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="memItemLeft" align="right" valign="top">Tuple[str, Checkpoint]&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrelab_1_1agents_1_1DQN_1_1DQN.html#ab5eba6790ccbd1d07171f0c2a5df2f93">load</a> (self, Optional[str] checkpoint_name=None, Optional[str] buffer_checkpoint_name=None)</td></tr>
<tr class="memdesc:ab5eba6790ccbd1d07171f0c2a5df2f93 inherit pub_methods_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="mdescLeft">&#160;</td><td class="mdescRight">Load an agent from the filesystem.  <br /></td></tr>
<tr class="separator:ab5eba6790ccbd1d07171f0c2a5df2f93 inherit pub_methods_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afaea756d733758ffbba110e0ebea7cdf inherit pub_methods_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrelab_1_1agents_1_1DQN_1_1DQN.html#afaea756d733758ffbba110e0ebea7cdf">as_dict</a> (self)</td></tr>
<tr class="separator:afaea756d733758ffbba110e0ebea7cdf inherit pub_methods_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a90e9b39f00d5c50fcdb6b506c9fd99fd inherit pub_methods_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="memItemLeft" align="right" valign="top">None&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrelab_1_1agents_1_1DQN_1_1DQN.html#a90e9b39f00d5c50fcdb6b506c9fd99fd">save</a> (self, str checkpoint_name, Optional[str] buffer_checkpoint_name=None)</td></tr>
<tr class="memdesc:a90e9b39f00d5c50fcdb6b506c9fd99fd inherit pub_methods_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="mdescLeft">&#160;</td><td class="mdescRight">Save the agent on the filesystem.  <br /></td></tr>
<tr class="separator:a90e9b39f00d5c50fcdb6b506c9fd99fd inherit pub_methods_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="inherit_header pub_methods_classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface"><td colspan="2" onclick="javascript:toggleInherit('pub_methods_classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface')"><img src="closed.png" alt="-"/>&#160;Public Member Functions inherited from <a class="el" href="classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface.html">relab.agents.AgentInterface.AgentInterface</a></td></tr>
<tr class="memitem:a37b65628d214627afae8cf7c8f576435 inherit pub_methods_classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface"><td class="memItemLeft" align="right" valign="top">None&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface.html#a37b65628d214627afae8cf7c8f576435">__init__</a> (self, bool <a class="el" href="classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface.html#aebe9410ff0c783d702877cba754bdfe4">training</a>=True)</td></tr>
<tr class="memdesc:a37b65628d214627afae8cf7c8f576435 inherit pub_methods_classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface"><td class="mdescLeft">&#160;</td><td class="mdescRight">Create an agent.  <br /></td></tr>
<tr class="separator:a37b65628d214627afae8cf7c8f576435 inherit pub_methods_classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5dc04ff5e1441ba6216f2f24e8d8c632 inherit pub_methods_classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface"><td class="memItemLeft" align="right" valign="top">ActionType&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface.html#a5dc04ff5e1441ba6216f2f24e8d8c632">step</a> (self, ObservationType obs)</td></tr>
<tr class="memdesc:a5dc04ff5e1441ba6216f2f24e8d8c632 inherit pub_methods_classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface"><td class="mdescLeft">&#160;</td><td class="mdescRight">Select the next action to perform in the environment.  <br /></td></tr>
<tr class="separator:a5dc04ff5e1441ba6216f2f24e8d8c632 inherit pub_methods_classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acb6aee67e6278cd5230ab2808f774577 inherit pub_methods_classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface"><td class="memItemLeft" align="right" valign="top">None&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface.html#acb6aee67e6278cd5230ab2808f774577">train</a> (self, Env env)</td></tr>
<tr class="memdesc:acb6aee67e6278cd5230ab2808f774577 inherit pub_methods_classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface"><td class="mdescLeft">&#160;</td><td class="mdescRight">Train the agent in the gym environment passed as parameters.  <br /></td></tr>
<tr class="separator:acb6aee67e6278cd5230ab2808f774577 inherit pub_methods_classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a162eb28fb9a698f2a58908c4a1d6110e inherit pub_methods_classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface"><td class="memItemLeft" align="right" valign="top">Tuple[str, Checkpoint]&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface.html#a162eb28fb9a698f2a58908c4a1d6110e">load</a> (self, Optional[str] checkpoint_name=None, Optional[str] buffer_checkpoint_name=None)</td></tr>
<tr class="memdesc:a162eb28fb9a698f2a58908c4a1d6110e inherit pub_methods_classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface"><td class="mdescLeft">&#160;</td><td class="mdescRight">Load an agent from the filesystem.  <br /></td></tr>
<tr class="separator:a162eb28fb9a698f2a58908c4a1d6110e inherit pub_methods_classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4725a741348861a5c9f9395df508f063 inherit pub_methods_classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface.html#a4725a741348861a5c9f9395df508f063">as_dict</a> (self)</td></tr>
<tr class="separator:a4725a741348861a5c9f9395df508f063 inherit pub_methods_classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a19be8462f89a85eb5c6f4dc9c07201f9 inherit pub_methods_classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface"><td class="memItemLeft" align="right" valign="top">None&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface.html#a19be8462f89a85eb5c6f4dc9c07201f9">save</a> (self, str checkpoint_name, Optional[str] buffer_checkpoint_name=None)</td></tr>
<tr class="memdesc:a19be8462f89a85eb5c6f4dc9c07201f9 inherit pub_methods_classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface"><td class="mdescLeft">&#160;</td><td class="mdescRight">Save the agent on the filesystem.  <br /></td></tr>
<tr class="separator:a19be8462f89a85eb5c6f4dc9c07201f9 inherit pub_methods_classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5766245d893fd33acda1bb041e6a5173 inherit pub_methods_classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface"><td class="memItemLeft" align="right" valign="top">None&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface.html#a5766245d893fd33acda1bb041e6a5173">demo</a> (self, Env env, str gif_name, int max_frames=10000)</td></tr>
<tr class="memdesc:a5766245d893fd33acda1bb041e6a5173 inherit pub_methods_classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface"><td class="mdescLeft">&#160;</td><td class="mdescRight">Demonstrate the agent policy in the gym environment passed as parameters.  <br /></td></tr>
<tr class="separator:a5766245d893fd33acda1bb041e6a5173 inherit pub_methods_classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af4ab3f64e484947cb12ce99df56d9e4a inherit pub_methods_classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface"><td class="memItemLeft" align="right" valign="top">None&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface.html#af4ab3f64e484947cb12ce99df56d9e4a">report</a> (self, SupportsFloat reward, bool done, Dict[str, Any] model_losses=None)</td></tr>
<tr class="memdesc:af4ab3f64e484947cb12ce99df56d9e4a inherit pub_methods_classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface"><td class="mdescLeft">&#160;</td><td class="mdescRight">Keep track of the last episodic rewards, episode length, and time elapse since last training iteration.  <br /></td></tr>
<tr class="separator:af4ab3f64e484947cb12ce99df56d9e4a inherit pub_methods_classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a92338de60d467d97e4c1939844b8533b inherit pub_methods_classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface"><td class="memItemLeft" align="right" valign="top">None&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface.html#a92338de60d467d97e4c1939844b8533b">log_performance_in_tensorboard</a> (self)</td></tr>
<tr class="memdesc:a92338de60d467d97e4c1939844b8533b inherit pub_methods_classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface"><td class="mdescLeft">&#160;</td><td class="mdescRight">Log the agent performance in tensorboard, if the internal queue.  <br /></td></tr>
<tr class="separator:a92338de60d467d97e4c1939844b8533b inherit pub_methods_classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="inherited" name="inherited"></a>
Additional Inherited Members</h2></td></tr>
<tr class="inherit_header pub_static_methods_classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface"><td colspan="2" onclick="javascript:toggleInherit('pub_static_methods_classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface')"><img src="closed.png" alt="-"/>&#160;Static Public Member Functions inherited from <a class="el" href="classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface.html">relab.agents.AgentInterface.AgentInterface</a></td></tr>
<tr class="memitem:ac2a05fd6065be94e8f17e6626f8badae inherit pub_static_methods_classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface"><td class="memItemLeft" align="right" valign="top">Optional[str]&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface.html#ac2a05fd6065be94e8f17e6626f8badae">get_latest_checkpoint</a> (str regex=r&quot;model_\d+.pt&quot;)</td></tr>
<tr class="memdesc:ac2a05fd6065be94e8f17e6626f8badae inherit pub_static_methods_classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface"><td class="mdescLeft">&#160;</td><td class="mdescRight">Get the latest checkpoint file matching the regex.  <br /></td></tr>
<tr class="separator:ac2a05fd6065be94e8f17e6626f8badae inherit pub_static_methods_classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af346001fffd195e37ff78eb7ffc73ac6 inherit pub_static_methods_classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface"><td class="memItemLeft" align="right" valign="top">Callable&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface.html#af346001fffd195e37ff78eb7ffc73ac6">get_replay_buffer</a> (<a class="el" href="classrelab_1_1agents_1_1AgentInterface_1_1ReplayType.html">ReplayType</a> replay_type, float omega, float omega_is, int n_steps, float gamma=1.0)</td></tr>
<tr class="memdesc:af346001fffd195e37ff78eb7ffc73ac6 inherit pub_static_methods_classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface"><td class="mdescLeft">&#160;</td><td class="mdescRight">Retrieve the constructor of the replay buffer requested as parameters.  <br /></td></tr>
<tr class="separator:af346001fffd195e37ff78eb7ffc73ac6 inherit pub_static_methods_classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a704603931adc5148ee15311a72056935 inherit pub_static_methods_classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface"><td class="memItemLeft" align="right" valign="top">Any&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface.html#a704603931adc5148ee15311a72056935">safe_load</a> (Checkpoint checkpoint, str key)</td></tr>
<tr class="memdesc:a704603931adc5148ee15311a72056935 inherit pub_static_methods_classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface"><td class="mdescLeft">&#160;</td><td class="mdescRight">Load the value corresponding to the key in the checkpoint.  <br /></td></tr>
<tr class="separator:a704603931adc5148ee15311a72056935 inherit pub_static_methods_classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a74a42b5a97d74fb792cb43455d274a22 inherit pub_static_methods_classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface"><td class="memItemLeft" align="right" valign="top">Optimizer&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface.html#a74a42b5a97d74fb792cb43455d274a22">safe_load_optimizer</a> (Checkpoint checkpoint, Union[Iterator[Parameter], List[Parameter]] params, float learning_rate, float adam_eps)</td></tr>
<tr class="memdesc:a74a42b5a97d74fb792cb43455d274a22 inherit pub_static_methods_classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface"><td class="mdescLeft">&#160;</td><td class="mdescRight">Load the Adam optimizer from the checkpoint safely.  <br /></td></tr>
<tr class="separator:a74a42b5a97d74fb792cb43455d274a22 inherit pub_static_methods_classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="inherit_header pub_attribs_classrelab_1_1agents_1_1DQN_1_1DQN"><td colspan="2" onclick="javascript:toggleInherit('pub_attribs_classrelab_1_1agents_1_1DQN_1_1DQN')"><img src="closed.png" alt="-"/>&#160;Public Attributes inherited from <a class="el" href="classrelab_1_1agents_1_1DQN_1_1DQN.html">relab.agents.DQN.DQN</a></td></tr>
<tr class="memitem:a2587135d7d9055a60ba69025563769ae inherit pub_attribs_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="memItemLeft" align="right" valign="top"><a id="a2587135d7d9055a60ba69025563769ae" name="a2587135d7d9055a60ba69025563769ae"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>gamma</b></td></tr>
<tr class="memdesc:a2587135d7d9055a60ba69025563769ae inherit pub_attribs_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="mdescLeft">&#160;</td><td class="mdescRight">Discount factor for future rewards (between 0 and 1). <br /></td></tr>
<tr class="separator:a2587135d7d9055a60ba69025563769ae inherit pub_attribs_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afbdb81a773ff9c8974fcd3cb0ac6d25d inherit pub_attribs_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="memItemLeft" align="right" valign="top"><a id="afbdb81a773ff9c8974fcd3cb0ac6d25d" name="afbdb81a773ff9c8974fcd3cb0ac6d25d"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>learning_rate</b></td></tr>
<tr class="memdesc:afbdb81a773ff9c8974fcd3cb0ac6d25d inherit pub_attribs_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="mdescLeft">&#160;</td><td class="mdescRight">Learning rate for the optimizer. <br /></td></tr>
<tr class="separator:afbdb81a773ff9c8974fcd3cb0ac6d25d inherit pub_attribs_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad9e7a11caa27eca86e0460f84342c3f9 inherit pub_attribs_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="memItemLeft" align="right" valign="top"><a id="ad9e7a11caa27eca86e0460f84342c3f9" name="ad9e7a11caa27eca86e0460f84342c3f9"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>buffer_size</b></td></tr>
<tr class="memdesc:ad9e7a11caa27eca86e0460f84342c3f9 inherit pub_attribs_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="mdescLeft">&#160;</td><td class="mdescRight">Maximum number of transitions stored in the replay buffer. <br /></td></tr>
<tr class="separator:ad9e7a11caa27eca86e0460f84342c3f9 inherit pub_attribs_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ace1892c0e7a64acdb36c5cca15f944e0 inherit pub_attribs_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="memItemLeft" align="right" valign="top"><a id="ace1892c0e7a64acdb36c5cca15f944e0" name="ace1892c0e7a64acdb36c5cca15f944e0"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>batch_size</b></td></tr>
<tr class="memdesc:ace1892c0e7a64acdb36c5cca15f944e0 inherit pub_attribs_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="mdescLeft">&#160;</td><td class="mdescRight">Number of transitions sampled per learning update. <br /></td></tr>
<tr class="separator:ace1892c0e7a64acdb36c5cca15f944e0 inherit pub_attribs_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aabd2a4bbb70d1ea02543593983318b9d inherit pub_attribs_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="memItemLeft" align="right" valign="top"><a id="aabd2a4bbb70d1ea02543593983318b9d" name="aabd2a4bbb70d1ea02543593983318b9d"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>target_update_interval</b></td></tr>
<tr class="memdesc:aabd2a4bbb70d1ea02543593983318b9d inherit pub_attribs_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="mdescLeft">&#160;</td><td class="mdescRight">Number of training steps between target network updates. <br /></td></tr>
<tr class="separator:aabd2a4bbb70d1ea02543593983318b9d inherit pub_attribs_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac24fbc141ab886ed3acc8231809dfa3a inherit pub_attribs_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="memItemLeft" align="right" valign="top"><a id="ac24fbc141ab886ed3acc8231809dfa3a" name="ac24fbc141ab886ed3acc8231809dfa3a"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>learning_starts</b></td></tr>
<tr class="memdesc:ac24fbc141ab886ed3acc8231809dfa3a inherit pub_attribs_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="mdescLeft">&#160;</td><td class="mdescRight">Step count at which learning begins. <br /></td></tr>
<tr class="separator:ac24fbc141ab886ed3acc8231809dfa3a inherit pub_attribs_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aaa183522b6ce8b71287e535597a6f04f inherit pub_attribs_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="memItemLeft" align="right" valign="top"><a id="aaa183522b6ce8b71287e535597a6f04f" name="aaa183522b6ce8b71287e535597a6f04f"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>kappa</b></td></tr>
<tr class="memdesc:aaa183522b6ce8b71287e535597a6f04f inherit pub_attribs_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="mdescLeft">&#160;</td><td class="mdescRight">Parameter for the quantile Huber loss (used in QR-DQN). <br /></td></tr>
<tr class="separator:aaa183522b6ce8b71287e535597a6f04f inherit pub_attribs_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2d767c31ee310a484c1b532557421776 inherit pub_attribs_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="memItemLeft" align="right" valign="top"><a id="a2d767c31ee310a484c1b532557421776" name="a2d767c31ee310a484c1b532557421776"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>adam_eps</b></td></tr>
<tr class="memdesc:a2d767c31ee310a484c1b532557421776 inherit pub_attribs_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="mdescLeft">&#160;</td><td class="mdescRight">Epsilon parameter for the Adam optimizer. <br /></td></tr>
<tr class="separator:a2d767c31ee310a484c1b532557421776 inherit pub_attribs_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5df9017e12bc717732e49b9e9f8ce255 inherit pub_attribs_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="memItemLeft" align="right" valign="top"><a id="a5df9017e12bc717732e49b9e9f8ce255" name="a5df9017e12bc717732e49b9e9f8ce255"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>n_atoms</b></td></tr>
<tr class="memdesc:a5df9017e12bc717732e49b9e9f8ce255 inherit pub_attribs_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="mdescLeft">&#160;</td><td class="mdescRight">Number of atoms used to approximate the return distribution. <br /></td></tr>
<tr class="separator:a5df9017e12bc717732e49b9e9f8ce255 inherit pub_attribs_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8bc4145119334efced67f11d1fa11046 inherit pub_attribs_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="memItemLeft" align="right" valign="top"><a id="a8bc4145119334efced67f11d1fa11046" name="a8bc4145119334efced67f11d1fa11046"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>v_min</b></td></tr>
<tr class="memdesc:a8bc4145119334efced67f11d1fa11046 inherit pub_attribs_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="mdescLeft">&#160;</td><td class="mdescRight">Minimum value for the return distribution support. <br /></td></tr>
<tr class="separator:a8bc4145119334efced67f11d1fa11046 inherit pub_attribs_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1704a1876e59896f48375bb63e96a2ca inherit pub_attribs_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="memItemLeft" align="right" valign="top"><a id="a1704a1876e59896f48375bb63e96a2ca" name="a1704a1876e59896f48375bb63e96a2ca"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>v_max</b></td></tr>
<tr class="memdesc:a1704a1876e59896f48375bb63e96a2ca inherit pub_attribs_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="mdescLeft">&#160;</td><td class="mdescRight">Maximum value for the return distribution support. <br /></td></tr>
<tr class="separator:a1704a1876e59896f48375bb63e96a2ca inherit pub_attribs_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3073c515322440f72bea0dc53858b16f inherit pub_attribs_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="memItemLeft" align="right" valign="top"><a id="a3073c515322440f72bea0dc53858b16f" name="a3073c515322440f72bea0dc53858b16f"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>n_actions</b></td></tr>
<tr class="memdesc:a3073c515322440f72bea0dc53858b16f inherit pub_attribs_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="mdescLeft">&#160;</td><td class="mdescRight">Number of possible actions in the environment. <br /></td></tr>
<tr class="separator:a3073c515322440f72bea0dc53858b16f inherit pub_attribs_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa1f80ea708eea38b8b46c9c96220abe6 inherit pub_attribs_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="memItemLeft" align="right" valign="top"><a id="aa1f80ea708eea38b8b46c9c96220abe6" name="aa1f80ea708eea38b8b46c9c96220abe6"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>n_steps</b></td></tr>
<tr class="memdesc:aa1f80ea708eea38b8b46c9c96220abe6 inherit pub_attribs_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="mdescLeft">&#160;</td><td class="mdescRight">Number of steps for multi-step learning. <br /></td></tr>
<tr class="separator:aa1f80ea708eea38b8b46c9c96220abe6 inherit pub_attribs_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a892b68fea851e507f510667be9971056 inherit pub_attribs_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="memItemLeft" align="right" valign="top"><a id="a892b68fea851e507f510667be9971056" name="a892b68fea851e507f510667be9971056"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>omega</b></td></tr>
<tr class="memdesc:a892b68fea851e507f510667be9971056 inherit pub_attribs_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="mdescLeft">&#160;</td><td class="mdescRight">Exponent for prioritization in the replay buffer. <br /></td></tr>
<tr class="separator:a892b68fea851e507f510667be9971056 inherit pub_attribs_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae5523e1136c036b6e1b54f40b7af0ea0 inherit pub_attribs_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="memItemLeft" align="right" valign="top"><a id="ae5523e1136c036b6e1b54f40b7af0ea0" name="ae5523e1136c036b6e1b54f40b7af0ea0"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>omega_is</b></td></tr>
<tr class="memdesc:ae5523e1136c036b6e1b54f40b7af0ea0 inherit pub_attribs_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="mdescLeft">&#160;</td><td class="mdescRight">Exponent for importance sampling correction. <br /></td></tr>
<tr class="separator:ae5523e1136c036b6e1b54f40b7af0ea0 inherit pub_attribs_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8eaa62eca1d1b02b091befeaa854b4e8 inherit pub_attribs_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="memItemLeft" align="right" valign="top"><a id="a8eaa62eca1d1b02b091befeaa854b4e8" name="a8eaa62eca1d1b02b091befeaa854b4e8"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>replay_type</b></td></tr>
<tr class="memdesc:a8eaa62eca1d1b02b091befeaa854b4e8 inherit pub_attribs_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="mdescLeft">&#160;</td><td class="mdescRight">Type of experience replay buffer being used. <br /></td></tr>
<tr class="separator:a8eaa62eca1d1b02b091befeaa854b4e8 inherit pub_attribs_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa09f06ba76e978d3571ede38ce61209e inherit pub_attribs_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="memItemLeft" align="right" valign="top"><a id="aa09f06ba76e978d3571ede38ce61209e" name="aa09f06ba76e978d3571ede38ce61209e"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>loss_type</b></td></tr>
<tr class="memdesc:aa09f06ba76e978d3571ede38ce61209e inherit pub_attribs_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="mdescLeft">&#160;</td><td class="mdescRight">Type of loss function used for training. <br /></td></tr>
<tr class="separator:aa09f06ba76e978d3571ede38ce61209e inherit pub_attribs_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac0794239af64612da5c0ae9a1b68e18b inherit pub_attribs_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="memItemLeft" align="right" valign="top"><a id="ac0794239af64612da5c0ae9a1b68e18b" name="ac0794239af64612da5c0ae9a1b68e18b"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>network_type</b></td></tr>
<tr class="memdesc:ac0794239af64612da5c0ae9a1b68e18b inherit pub_attribs_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="mdescLeft">&#160;</td><td class="mdescRight">Type of neural network architecture used. <br /></td></tr>
<tr class="separator:ac0794239af64612da5c0ae9a1b68e18b inherit pub_attribs_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a019621ab0c19444789434487859875f5 inherit pub_attribs_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="memItemLeft" align="right" valign="top"><a id="a019621ab0c19444789434487859875f5" name="a019621ab0c19444789434487859875f5"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>epsilon_schedule</b></td></tr>
<tr class="memdesc:a019621ab0c19444789434487859875f5 inherit pub_attribs_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="mdescLeft">&#160;</td><td class="mdescRight">Schedule for the exploration parameter epsilon. <br /></td></tr>
<tr class="separator:a019621ab0c19444789434487859875f5 inherit pub_attribs_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9eb06476c0b741badf76432c43cf2ea7 inherit pub_attribs_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="memItemLeft" align="right" valign="top"><a id="a9eb06476c0b741badf76432c43cf2ea7" name="a9eb06476c0b741badf76432c43cf2ea7"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>epsilon</b></td></tr>
<tr class="memdesc:a9eb06476c0b741badf76432c43cf2ea7 inherit pub_attribs_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="mdescLeft">&#160;</td><td class="mdescRight">Scheduler for the exploration parameter epsilon. <br /></td></tr>
<tr class="separator:a9eb06476c0b741badf76432c43cf2ea7 inherit pub_attribs_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7a9631f575f0ebb622e226bbd9182969 inherit pub_attribs_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="memItemLeft" align="right" valign="top"><a id="a7a9631f575f0ebb622e226bbd9182969" name="a7a9631f575f0ebb622e226bbd9182969"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>loss</b></td></tr>
<tr class="memdesc:a7a9631f575f0ebb622e226bbd9182969 inherit pub_attribs_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="mdescLeft">&#160;</td><td class="mdescRight">Loss function used for computing gradients. <br /></td></tr>
<tr class="separator:a7a9631f575f0ebb622e226bbd9182969 inherit pub_attribs_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a69a48926f82f3db5a5ba3eefd4c41021 inherit pub_attribs_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="memItemLeft" align="right" valign="top"><a id="a69a48926f82f3db5a5ba3eefd4c41021" name="a69a48926f82f3db5a5ba3eefd4c41021"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>value_net</b></td></tr>
<tr class="memdesc:a69a48926f82f3db5a5ba3eefd4c41021 inherit pub_attribs_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="mdescLeft">&#160;</td><td class="mdescRight">The value network that approximates the Q-value function. <br /></td></tr>
<tr class="separator:a69a48926f82f3db5a5ba3eefd4c41021 inherit pub_attribs_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab4d3529d1a839eacdf67ddbc7717c254 inherit pub_attribs_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="memItemLeft" align="right" valign="top"><a id="ab4d3529d1a839eacdf67ddbc7717c254" name="ab4d3529d1a839eacdf67ddbc7717c254"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>target_net</b></td></tr>
<tr class="memdesc:ab4d3529d1a839eacdf67ddbc7717c254 inherit pub_attribs_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="mdescLeft">&#160;</td><td class="mdescRight">The target network, which is a copy of the value network synchronized periodically. <br /></td></tr>
<tr class="separator:ab4d3529d1a839eacdf67ddbc7717c254 inherit pub_attribs_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af757bc63e240c7b7b8ef0bfea7257a55 inherit pub_attribs_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="memItemLeft" align="right" valign="top"><a id="af757bc63e240c7b7b8ef0bfea7257a55" name="af757bc63e240c7b7b8ef0bfea7257a55"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>optimizer</b></td></tr>
<tr class="memdesc:af757bc63e240c7b7b8ef0bfea7257a55 inherit pub_attribs_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="mdescLeft">&#160;</td><td class="mdescRight">Adam optimizer for training the value network. <br /></td></tr>
<tr class="separator:af757bc63e240c7b7b8ef0bfea7257a55 inherit pub_attribs_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a18261ebe1ac3a6e98d3bc2883545154c inherit pub_attribs_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="memItemLeft" align="right" valign="top"><a id="a18261ebe1ac3a6e98d3bc2883545154c" name="a18261ebe1ac3a6e98d3bc2883545154c"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>buffer</b></td></tr>
<tr class="memdesc:a18261ebe1ac3a6e98d3bc2883545154c inherit pub_attribs_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="mdescLeft">&#160;</td><td class="mdescRight">Experience replay buffer for storing transitions. <br /></td></tr>
<tr class="separator:a18261ebe1ac3a6e98d3bc2883545154c inherit pub_attribs_classrelab_1_1agents_1_1DQN_1_1DQN"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="inherit_header pub_attribs_classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface"><td colspan="2" onclick="javascript:toggleInherit('pub_attribs_classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface')"><img src="closed.png" alt="-"/>&#160;Public Attributes inherited from <a class="el" href="classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface.html">relab.agents.AgentInterface.AgentInterface</a></td></tr>
<tr class="memitem:aebe9410ff0c783d702877cba754bdfe4 inherit pub_attribs_classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface"><td class="memItemLeft" align="right" valign="top"><a id="aebe9410ff0c783d702877cba754bdfe4" name="aebe9410ff0c783d702877cba754bdfe4"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>training</b></td></tr>
<tr class="memdesc:aebe9410ff0c783d702877cba754bdfe4 inherit pub_attribs_classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface"><td class="mdescLeft">&#160;</td><td class="mdescRight">Flag indicating whether the agent is in training mode. <br /></td></tr>
<tr class="separator:aebe9410ff0c783d702877cba754bdfe4 inherit pub_attribs_classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af9265d05f4810ac9f1e8a7b81fa2b3e4 inherit pub_attribs_classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface"><td class="memItemLeft" align="right" valign="top"><a id="af9265d05f4810ac9f1e8a7b81fa2b3e4" name="af9265d05f4810ac9f1e8a7b81fa2b3e4"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>device</b></td></tr>
<tr class="memdesc:af9265d05f4810ac9f1e8a7b81fa2b3e4 inherit pub_attribs_classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface"><td class="mdescLeft">&#160;</td><td class="mdescRight">The device (CPU/GPU) used for training computations. <br /></td></tr>
<tr class="separator:af9265d05f4810ac9f1e8a7b81fa2b3e4 inherit pub_attribs_classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2893cb65b44407a56a2063e76f46b084 inherit pub_attribs_classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface"><td class="memItemLeft" align="right" valign="top"><a id="a2893cb65b44407a56a2063e76f46b084" name="a2893cb65b44407a56a2063e76f46b084"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>max_queue_len</b></td></tr>
<tr class="memdesc:a2893cb65b44407a56a2063e76f46b084 inherit pub_attribs_classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface"><td class="mdescLeft">&#160;</td><td class="mdescRight">Maximum length for metric tracking queues (e.g., rewards, losses). <br /></td></tr>
<tr class="separator:a2893cb65b44407a56a2063e76f46b084 inherit pub_attribs_classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a57c5cb4f2b2a27f6f493dc2cb35204de inherit pub_attribs_classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface"><td class="memItemLeft" align="right" valign="top"><a id="a57c5cb4f2b2a27f6f493dc2cb35204de" name="a57c5cb4f2b2a27f6f493dc2cb35204de"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>current_step</b></td></tr>
<tr class="memdesc:a57c5cb4f2b2a27f6f493dc2cb35204de inherit pub_attribs_classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface"><td class="mdescLeft">&#160;</td><td class="mdescRight">Counter tracking the number of training steps performed. <br /></td></tr>
<tr class="separator:a57c5cb4f2b2a27f6f493dc2cb35204de inherit pub_attribs_classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ada135459aeaa08b56654573f26d9d164 inherit pub_attribs_classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface"><td class="memItemLeft" align="right" valign="top"><a id="ada135459aeaa08b56654573f26d9d164" name="ada135459aeaa08b56654573f26d9d164"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>vfe_losses</b></td></tr>
<tr class="memdesc:ada135459aeaa08b56654573f26d9d164 inherit pub_attribs_classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface"><td class="mdescLeft">&#160;</td><td class="mdescRight">Queue containing the last variational free energy loss values. <br /></td></tr>
<tr class="separator:ada135459aeaa08b56654573f26d9d164 inherit pub_attribs_classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4918c5297a7d20739113e60d376d54b0 inherit pub_attribs_classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface"><td class="memItemLeft" align="right" valign="top"><a id="a4918c5297a7d20739113e60d376d54b0" name="a4918c5297a7d20739113e60d376d54b0"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>betas</b></td></tr>
<tr class="memdesc:a4918c5297a7d20739113e60d376d54b0 inherit pub_attribs_classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface"><td class="mdescLeft">&#160;</td><td class="mdescRight">Queue containing the last beta values for variational inference. <br /></td></tr>
<tr class="separator:a4918c5297a7d20739113e60d376d54b0 inherit pub_attribs_classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a228b708b6845c61ae7fb1b263820e972 inherit pub_attribs_classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface"><td class="memItemLeft" align="right" valign="top"><a id="a228b708b6845c61ae7fb1b263820e972" name="a228b708b6845c61ae7fb1b263820e972"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>log_likelihoods</b></td></tr>
<tr class="memdesc:a228b708b6845c61ae7fb1b263820e972 inherit pub_attribs_classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface"><td class="mdescLeft">&#160;</td><td class="mdescRight">Queue containing the last log-likelihood values. <br /></td></tr>
<tr class="separator:a228b708b6845c61ae7fb1b263820e972 inherit pub_attribs_classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a50846610d0bef5788babfada7b23bd7c inherit pub_attribs_classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface"><td class="memItemLeft" align="right" valign="top"><a id="a50846610d0bef5788babfada7b23bd7c" name="a50846610d0bef5788babfada7b23bd7c"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>kl_divergences</b></td></tr>
<tr class="memdesc:a50846610d0bef5788babfada7b23bd7c inherit pub_attribs_classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface"><td class="mdescLeft">&#160;</td><td class="mdescRight">Queue containing the last KL-divergence values. <br /></td></tr>
<tr class="separator:a50846610d0bef5788babfada7b23bd7c inherit pub_attribs_classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afd45587d464b4589f99dffc60c91c86d inherit pub_attribs_classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface"><td class="memItemLeft" align="right" valign="top"><a id="afd45587d464b4589f99dffc60c91c86d" name="afd45587d464b4589f99dffc60c91c86d"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>process</b></td></tr>
<tr class="memdesc:afd45587d464b4589f99dffc60c91c86d inherit pub_attribs_classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface"><td class="mdescLeft">&#160;</td><td class="mdescRight">Object representing the current process, used to track memory usage. <br /></td></tr>
<tr class="separator:afd45587d464b4589f99dffc60c91c86d inherit pub_attribs_classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a01dbb8f53af242be4950b87001457051 inherit pub_attribs_classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface"><td class="memItemLeft" align="right" valign="top"><a id="a01dbb8f53af242be4950b87001457051" name="a01dbb8f53af242be4950b87001457051"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>virtual_memory</b></td></tr>
<tr class="memdesc:a01dbb8f53af242be4950b87001457051 inherit pub_attribs_classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface"><td class="mdescLeft">&#160;</td><td class="mdescRight">Queue tracking virtual memory usage over time. <br /></td></tr>
<tr class="separator:a01dbb8f53af242be4950b87001457051 inherit pub_attribs_classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afc8a86652d557c030960e658bcffc7bf inherit pub_attribs_classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface"><td class="memItemLeft" align="right" valign="top"><a id="afc8a86652d557c030960e658bcffc7bf" name="afc8a86652d557c030960e658bcffc7bf"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>residential_memory</b></td></tr>
<tr class="memdesc:afc8a86652d557c030960e658bcffc7bf inherit pub_attribs_classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface"><td class="mdescLeft">&#160;</td><td class="mdescRight">Queue tracking residential memory usage over time. <br /></td></tr>
<tr class="separator:afc8a86652d557c030960e658bcffc7bf inherit pub_attribs_classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5391a5dc70168153d9f2870c77c08817 inherit pub_attribs_classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface"><td class="memItemLeft" align="right" valign="top"><a id="a5391a5dc70168153d9f2870c77c08817" name="a5391a5dc70168153d9f2870c77c08817"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>episodic_rewards</b></td></tr>
<tr class="memdesc:a5391a5dc70168153d9f2870c77c08817 inherit pub_attribs_classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface"><td class="mdescLeft">&#160;</td><td class="mdescRight">Queue containing the last episodic reward values. <br /></td></tr>
<tr class="separator:a5391a5dc70168153d9f2870c77c08817 inherit pub_attribs_classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab4a9667415d86d25f96a2b24192df7b0 inherit pub_attribs_classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface"><td class="memItemLeft" align="right" valign="top"><a id="ab4a9667415d86d25f96a2b24192df7b0" name="ab4a9667415d86d25f96a2b24192df7b0"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>current_episodic_reward</b></td></tr>
<tr class="memdesc:ab4a9667415d86d25f96a2b24192df7b0 inherit pub_attribs_classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface"><td class="mdescLeft">&#160;</td><td class="mdescRight">Accumulator for the current episode's reward. <br /></td></tr>
<tr class="separator:ab4a9667415d86d25f96a2b24192df7b0 inherit pub_attribs_classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:add513abea2b924b9ff01ea780e615226 inherit pub_attribs_classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface"><td class="memItemLeft" align="right" valign="top"><a id="add513abea2b924b9ff01ea780e615226" name="add513abea2b924b9ff01ea780e615226"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>time_elapsed</b></td></tr>
<tr class="memdesc:add513abea2b924b9ff01ea780e615226 inherit pub_attribs_classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface"><td class="mdescLeft">&#160;</td><td class="mdescRight">Queue containing the time elapsed between consecutive training iterations. <br /></td></tr>
<tr class="separator:add513abea2b924b9ff01ea780e615226 inherit pub_attribs_classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3946d85e422e39dfb53bdcf0bdb157e2 inherit pub_attribs_classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface"><td class="memItemLeft" align="right" valign="top"><a id="a3946d85e422e39dfb53bdcf0bdb157e2" name="a3946d85e422e39dfb53bdcf0bdb157e2"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>last_time</b></td></tr>
<tr class="memdesc:a3946d85e422e39dfb53bdcf0bdb157e2 inherit pub_attribs_classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface"><td class="mdescLeft">&#160;</td><td class="mdescRight">Timestamp of the last training iteration. <br /></td></tr>
<tr class="separator:a3946d85e422e39dfb53bdcf0bdb157e2 inherit pub_attribs_classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab9e85b5ccd071a9bd1b31108af768b7f inherit pub_attribs_classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface"><td class="memItemLeft" align="right" valign="top"><a id="ab9e85b5ccd071a9bd1b31108af768b7f" name="ab9e85b5ccd071a9bd1b31108af768b7f"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>episode_lengths</b></td></tr>
<tr class="memdesc:ab9e85b5ccd071a9bd1b31108af768b7f inherit pub_attribs_classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface"><td class="mdescLeft">&#160;</td><td class="mdescRight">Queue containing the lengths of recent episodes. <br /></td></tr>
<tr class="separator:ab9e85b5ccd071a9bd1b31108af768b7f inherit pub_attribs_classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a57c7c72ae83d068259e19c2546fd7db9 inherit pub_attribs_classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface"><td class="memItemLeft" align="right" valign="top"><a id="a57c7c72ae83d068259e19c2546fd7db9" name="a57c7c72ae83d068259e19c2546fd7db9"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>current_episode_length</b></td></tr>
<tr class="memdesc:a57c7c72ae83d068259e19c2546fd7db9 inherit pub_attribs_classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface"><td class="mdescLeft">&#160;</td><td class="mdescRight">Counter for the current episode's length. <br /></td></tr>
<tr class="separator:a57c7c72ae83d068259e19c2546fd7db9 inherit pub_attribs_classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7ee2c0fa4c30526206bd7d02cfe321ce inherit pub_attribs_classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface"><td class="memItemLeft" align="right" valign="top"><a id="a7ee2c0fa4c30526206bd7d02cfe321ce" name="a7ee2c0fa4c30526206bd7d02cfe321ce"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>writer</b></td></tr>
<tr class="memdesc:a7ee2c0fa4c30526206bd7d02cfe321ce inherit pub_attribs_classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface"><td class="mdescLeft">&#160;</td><td class="mdescRight">TensorBoard summary writer for logging training metrics. <br /></td></tr>
<tr class="separator:a7ee2c0fa4c30526206bd7d02cfe321ce inherit pub_attribs_classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><p>Implements a multistep Deep Q-Network. </p>
<p>This implementation is based on the paper:</p>
<p><b>Learning to predict by the methods of temporal differences</b>, published in Machine learning, 3:9â€“44, 1988.</p>
<p>Authors:</p><ul>
<li>Richard S. Sutton </li>
</ul>
</div><h2 class="groupheader">Constructor &amp; Destructor Documentation</h2>
<a id="a8a4b112cc8177e91233bd1c5d090e008" name="a8a4b112cc8177e91233bd1c5d090e008"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8a4b112cc8177e91233bd1c5d090e008">&#9670;&#160;</a></span>__init__()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> None relab.agents.MDQN.MDQN.__init__ </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float &#160;</td>
          <td class="paramname"><em>gamma</em> = <code>0.99</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float &#160;</td>
          <td class="paramname"><em>learning_rate</em> = <code>0.00001</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int &#160;</td>
          <td class="paramname"><em>buffer_size</em> = <code>1000000</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int &#160;</td>
          <td class="paramname"><em>batch_size</em> = <code>32</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int &#160;</td>
          <td class="paramname"><em>learning_starts</em> = <code>200000</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int &#160;</td>
          <td class="paramname"><em>target_update_interval</em> = <code>40000</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float &#160;</td>
          <td class="paramname"><em>adam_eps</em> = <code>1.5e-4</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int &#160;</td>
          <td class="paramname"><em>n_actions</em> = <code>18</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int &#160;</td>
          <td class="paramname"><em>n_atoms</em> = <code>1</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>training</em> = <code>True</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int &#160;</td>
          <td class="paramname"><em>n_steps</em> = <code>3</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classrelab_1_1agents_1_1AgentInterface_1_1ReplayType.html">ReplayType</a> &#160;</td>
          <td class="paramname"><em>replay_type</em> = <code><a class="el" href="classrelab_1_1agents_1_1AgentInterface_1_1ReplayType.html#a4f90b2efe6b7277c4f764b18770ba4e5">ReplayType.MULTISTEP</a></code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classrelab_1_1agents_1_1DQN_1_1LossType.html">LossType</a> &#160;</td>
          <td class="paramname"><em>loss_type</em> = <code><a class="el" href="classrelab_1_1agents_1_1DQN_1_1LossType.html#a7fc4dd09dd09f4cad7e8b2f80525794f">LossType.DQN_SL1</a></code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classrelab_1_1agents_1_1DQN_1_1NetworkType.html">NetworkType</a> &#160;</td>
          <td class="paramname"><em>network_type</em> = <code><a class="el" href="classrelab_1_1agents_1_1DQN_1_1NetworkType.html#a151e691483dc02332cb23e2d3d9c88a8">NetworkType.DEFAULT</a></code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Create a DQN agent. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">gamma</td><td>the discount factor </td></tr>
    <tr><td class="paramname">learning_rate</td><td>the learning rate </td></tr>
    <tr><td class="paramname">buffer_size</td><td>the size of the replay buffer </td></tr>
    <tr><td class="paramname">batch_size</td><td>the size of the batches sampled from the replay buffer </td></tr>
    <tr><td class="paramname">learning_starts</td><td>the step at which learning starts </td></tr>
    <tr><td class="paramname">target_update_interval</td><td>number of training steps between two synchronization of the target </td></tr>
    <tr><td class="paramname">adam_eps</td><td>the epsilon parameter of the Adam optimizer </td></tr>
    <tr><td class="paramname">n_actions</td><td>the number of actions available to the agent </td></tr>
    <tr><td class="paramname">n_atoms</td><td>the number of atoms used to approximate the distribution over returns </td></tr>
    <tr><td class="paramname">training</td><td>True if the agent is being trained, False otherwise </td></tr>
    <tr><td class="paramname">n_steps</td><td>the number of steps for which rewards are accumulated in multistep Q-learning </td></tr>
    <tr><td class="paramname">replay_type</td><td>the type of replay buffer </td></tr>
    <tr><td class="paramname">loss_type</td><td>the loss to use during gradient descent </td></tr>
    <tr><td class="paramname">network_type</td><td>the network architecture to use for the value and target networks </td></tr>
  </table>
  </dd>
</dl>

<p>Reimplemented from <a class="el" href="classrelab_1_1agents_1_1DQN_1_1DQN.html#a2d91aced72b5b4b01098fba9e85abaf3">relab.agents.DQN.DQN</a>.</p>

</div>
</div>
<hr/>The documentation for this class was generated from the following file:<ul>
<li>relab/agents/MDQN.py</li>
</ul>
</div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><b>relab</b></li><li class="navelem"><b>agents</b></li><li class="navelem"><b>MDQN</b></li><li class="navelem"><a class="el" href="classrelab_1_1agents_1_1MDQN_1_1MDQN.html">MDQN</a></li>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.6 </li>
  </ul>
</div>
</body>
</html>
