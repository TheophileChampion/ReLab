<!-- HTML header for doxygen 1.9.8-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.6"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>ReLab | Documentation</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ðŸš€</text></svg>">
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<script type="text/javascript" src="doxygen-awesome-darkmode-toggle.js"></script>
<script type="text/javascript">
    DoxygenAwesomeDarkModeToggle.init()
</script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="doxygen-awesome.css" rel="stylesheet" type="text/css"/>
<link href="custom.css" rel="stylesheet" type="text/css"/>
<link href="doxygen-awesome-sidebar-only.css" rel="stylesheet" type="text/css"/>
<link href="doxygen-awesome-sidebar-only-darkmode-toggle.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectlogo"><img alt="Logo" src="relab-logo-only.png"/></td>
  <td id="projectalign">
   <div id="projectname">ReLab<span id="projectnumber">&#160;v1.0.0-b</span>
   </div>
   <div id="projectbrief">Reinforcement Learning Benchmarks</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.6 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(document).ready(function(){initNavTree('classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface.html',''); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div class="header">
  <div class="summary">
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="#pub-static-methods">Static Public Member Functions</a> &#124;
<a href="#pub-attribs">Public Attributes</a> &#124;
<a href="classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface-members.html">List of all members</a>  </div>
  <div class="headertitle"><div class="title">relab.agents.AgentInterface.AgentInterface Class Reference</div></div>
</div><!--header-->
<div class="contents">

<p>The interface that all agents must implement.  
 <a href="classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface.html#details">More...</a></p>
<div class="dynheader">
Inheritance diagram for relab.agents.AgentInterface.AgentInterface:</div>
<div class="dyncontent">
<div class="center"><img src="classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface__inherit__graph.png" border="0" usemap="#arelab_8agents_8AgentInterface_8AgentInterface_inherit__map" alt="Inheritance graph"/></div>
<map name="arelab_8agents_8AgentInterface_8AgentInterface_inherit__map" id="arelab_8agents_8AgentInterface_8AgentInterface_inherit__map">
<area shape="rect" title="The interface that all agents must implement." alt="" coords="103,630,309,670"/>
<area shape="rect" href="classrelab_1_1agents_1_1DQN_1_1DQN.html" title="Implements a Deep Q&#45;Network." alt="" coords="381,407,552,432"/>
<area shape="rect" href="classrelab_1_1agents_1_1Random_1_1Random.html" title="Implements an agent taking random actions." alt="" coords="357,637,576,663"/>
<area shape="rect" href="classrelab_1_1agents_1_1VariationalModel_1_1VariationalModel.html" title="The interface that all agents behaving randomly to learn a world models must implement." alt="" coords="378,845,555,885"/>
<area shape="rect" title=" " alt="" coords="5,637,55,663"/>
<area shape="rect" href="classrelab_1_1agents_1_1CDQN_1_1CDQN.html" title="Implements a Categorical Deep Q&#45;Network." alt="" coords="662,5,851,31"/>
<area shape="rect" href="classrelab_1_1agents_1_1DDQN_1_1DDQN.html" title="Implements a Double Deep Q&#45;Network." alt="" coords="661,55,852,80"/>
<area shape="rect" href="classrelab_1_1agents_1_1DuelingDDQN_1_1DuelingDDQN.html" title="Implements a Dueling Double Deep Q&#45;Network." alt="" coords="656,105,857,145"/>
<area shape="rect" href="classrelab_1_1agents_1_1DuelingDQN_1_1DuelingDQN.html" title="Implements a Dueling Deep Q&#45;Network." alt="" coords="661,169,852,209"/>
<area shape="rect" href="classrelab_1_1agents_1_1IQN_1_1IQN.html" title="Implement an Implicit Quantile Network." alt="" coords="677,233,836,259"/>
<area shape="rect" href="classrelab_1_1agents_1_1MDQN_1_1MDQN.html" title="Implements a multistep Deep Q&#45;Network." alt="" coords="659,283,854,308"/>
<area shape="rect" href="classrelab_1_1agents_1_1NoisyCDQN_1_1NoisyCDQN.html" title="Implement a Categorical Deep Q&#45;Network with noisy linear layers (NoisyCDQN)." alt="" coords="625,332,888,357"/>
<area shape="rect" href="classrelab_1_1agents_1_1NoisyDDQN_1_1NoisyDDQN.html" title="Implement a Double DQN with noisy linear layers." alt="" coords="624,381,889,407"/>
<area shape="rect" href="classrelab_1_1agents_1_1NoisyDQN_1_1NoisyDQN.html" title="Implement a DQN with noisy linear layers." alt="" coords="634,431,879,456"/>
<area shape="rect" href="classrelab_1_1agents_1_1PrioritizedDDQN_1_1PrioritizedDDQN.html" title="Implement a Double DQN with prioritized replay buffer." alt="" coords="670,481,843,521"/>
<area shape="rect" href="classrelab_1_1agents_1_1PrioritizedDQN_1_1PrioritizedDQN.html" title="Implement a DQN with prioritized replay buffer." alt="" coords="670,545,843,585"/>
<area shape="rect" href="classrelab_1_1agents_1_1PrioritizedMDQN_1_1PrioritizedMDQN.html" title="Implement a multistep DQN with prioritized replay buffer." alt="" coords="669,609,845,649"/>
<area shape="rect" href="classrelab_1_1agents_1_1QRDQN_1_1QRDQN.html" title="Implement a quantile regression Deep Q&#45;Network." alt="" coords="652,673,861,699"/>
<area shape="rect" href="classrelab_1_1agents_1_1RainbowDQN_1_1RainbowDQN.html" title="Implement a rainbow Deep Q&#45;Network." alt="" coords="658,723,855,763"/>
<area shape="rect" href="classrelab_1_1agents_1_1RainbowIQN_1_1RainbowIQN.html" title="Implement a rainbow implicit quantile network." alt="" coords="661,787,852,827"/>
<area shape="rect" href="classrelab_1_1agents_1_1HMM_1_1HMM.html" title="Implements a Hidden Markov Model." alt="" coords="667,852,846,877"/>
<area shape="rect" href="classrelab_1_1agents_1_1VAE_1_1VAE.html" title="Implements a Variational Auto&#45;Encoder (VAE) agent." alt="" coords="676,957,837,983"/>
<area shape="rect" href="classrelab_1_1agents_1_1BetaHMM_1_1BetaHMM.html" title="Implements a Beta Hidden Markov Model." alt="" coords="937,765,1176,791"/>
<area shape="rect" href="classrelab_1_1agents_1_1DiscreteHMM_1_1DiscreteHMM.html" title="Implements a Discrete Hidden Markov Model." alt="" coords="957,815,1156,855"/>
<area shape="rect" href="classrelab_1_1agents_1_1JointHMM_1_1JointHMM.html" title="Implements a Joint Hidden Markov Model." alt="" coords="938,880,1175,905"/>
<area shape="rect" href="classrelab_1_1agents_1_1BetaVAE_1_1BetaVAE.html" title="Implements a Beta Variational Auto&#45;Encoder." alt="" coords="946,929,1167,955"/>
<area shape="rect" href="classrelab_1_1agents_1_1DiscreteVAE_1_1DiscreteVAE.html" title="Implements a Discrete Variational Auto&#45;Encoder." alt="" coords="961,979,1152,1019"/>
<area shape="rect" href="classrelab_1_1agents_1_1JointVAE_1_1JointVAE.html" title="Implements a Joint Variational Auto&#45;Encoder." alt="" coords="947,1044,1166,1069"/>
</map>
<center><span class="legend">[<a target="top" href="graph_legend.html">legend</a>]</span></center></div>
<div class="dynheader">
Collaboration diagram for relab.agents.AgentInterface.AgentInterface:</div>
<div class="dyncontent">
<div class="center"><img src="classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface__coll__graph.png" border="0" usemap="#arelab_8agents_8AgentInterface_8AgentInterface_coll__map" alt="Collaboration graph"/></div>
<map name="arelab_8agents_8AgentInterface_8AgentInterface_coll__map" id="arelab_8agents_8AgentInterface_8AgentInterface_coll__map">
<area shape="rect" title="The interface that all agents must implement." alt="" coords="5,79,212,119"/>
<area shape="rect" title=" " alt="" coords="84,5,133,31"/>
</map>
<center><span class="legend">[<a target="top" href="graph_legend.html">legend</a>]</span></center></div>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pub-methods" name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:a37b65628d214627afae8cf7c8f576435"><td class="memItemLeft" align="right" valign="top">None&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface.html#a37b65628d214627afae8cf7c8f576435">__init__</a> (self, bool <a class="el" href="classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface.html#aebe9410ff0c783d702877cba754bdfe4">training</a>=True)</td></tr>
<tr class="memdesc:a37b65628d214627afae8cf7c8f576435"><td class="mdescLeft">&#160;</td><td class="mdescRight">Create an agent.  <br /></td></tr>
<tr class="separator:a37b65628d214627afae8cf7c8f576435"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5dc04ff5e1441ba6216f2f24e8d8c632"><td class="memItemLeft" align="right" valign="top">ActionType&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface.html#a5dc04ff5e1441ba6216f2f24e8d8c632">step</a> (self, ObservationType obs)</td></tr>
<tr class="memdesc:a5dc04ff5e1441ba6216f2f24e8d8c632"><td class="mdescLeft">&#160;</td><td class="mdescRight">Select the next action to perform in the environment.  <br /></td></tr>
<tr class="separator:a5dc04ff5e1441ba6216f2f24e8d8c632"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acb6aee67e6278cd5230ab2808f774577"><td class="memItemLeft" align="right" valign="top">None&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface.html#acb6aee67e6278cd5230ab2808f774577">train</a> (self, Env env)</td></tr>
<tr class="memdesc:acb6aee67e6278cd5230ab2808f774577"><td class="mdescLeft">&#160;</td><td class="mdescRight">Train the agent in the gym environment passed as parameters.  <br /></td></tr>
<tr class="separator:acb6aee67e6278cd5230ab2808f774577"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a162eb28fb9a698f2a58908c4a1d6110e"><td class="memItemLeft" align="right" valign="top">Tuple[str, Checkpoint]&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface.html#a162eb28fb9a698f2a58908c4a1d6110e">load</a> (self, Optional[str] checkpoint_name=None, Optional[str] buffer_checkpoint_name=None)</td></tr>
<tr class="memdesc:a162eb28fb9a698f2a58908c4a1d6110e"><td class="mdescLeft">&#160;</td><td class="mdescRight">Load an agent from the filesystem.  <br /></td></tr>
<tr class="separator:a162eb28fb9a698f2a58908c4a1d6110e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4725a741348861a5c9f9395df508f063"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface.html#a4725a741348861a5c9f9395df508f063">as_dict</a> (self)</td></tr>
<tr class="separator:a4725a741348861a5c9f9395df508f063"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a19be8462f89a85eb5c6f4dc9c07201f9"><td class="memItemLeft" align="right" valign="top">None&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface.html#a19be8462f89a85eb5c6f4dc9c07201f9">save</a> (self, str checkpoint_name, Optional[str] buffer_checkpoint_name=None)</td></tr>
<tr class="memdesc:a19be8462f89a85eb5c6f4dc9c07201f9"><td class="mdescLeft">&#160;</td><td class="mdescRight">Save the agent on the filesystem.  <br /></td></tr>
<tr class="separator:a19be8462f89a85eb5c6f4dc9c07201f9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5766245d893fd33acda1bb041e6a5173"><td class="memItemLeft" align="right" valign="top">None&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface.html#a5766245d893fd33acda1bb041e6a5173">demo</a> (self, Env env, str gif_name, int max_frames=10000)</td></tr>
<tr class="memdesc:a5766245d893fd33acda1bb041e6a5173"><td class="mdescLeft">&#160;</td><td class="mdescRight">Demonstrate the agent policy in the gym environment passed as parameters.  <br /></td></tr>
<tr class="separator:a5766245d893fd33acda1bb041e6a5173"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af4ab3f64e484947cb12ce99df56d9e4a"><td class="memItemLeft" align="right" valign="top">None&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface.html#af4ab3f64e484947cb12ce99df56d9e4a">report</a> (self, SupportsFloat reward, bool done, Dict[str, Any] model_losses=None)</td></tr>
<tr class="memdesc:af4ab3f64e484947cb12ce99df56d9e4a"><td class="mdescLeft">&#160;</td><td class="mdescRight">Keep track of the last episodic rewards, episode length, and time elapse since last training iteration.  <br /></td></tr>
<tr class="separator:af4ab3f64e484947cb12ce99df56d9e4a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a92338de60d467d97e4c1939844b8533b"><td class="memItemLeft" align="right" valign="top">None&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface.html#a92338de60d467d97e4c1939844b8533b">log_performance_in_tensorboard</a> (self)</td></tr>
<tr class="memdesc:a92338de60d467d97e4c1939844b8533b"><td class="mdescLeft">&#160;</td><td class="mdescRight">Log the agent performance in tensorboard, if the internal queue.  <br /></td></tr>
<tr class="separator:a92338de60d467d97e4c1939844b8533b"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pub-static-methods" name="pub-static-methods"></a>
Static Public Member Functions</h2></td></tr>
<tr class="memitem:ac2a05fd6065be94e8f17e6626f8badae"><td class="memItemLeft" align="right" valign="top">Optional[str]&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface.html#ac2a05fd6065be94e8f17e6626f8badae">get_latest_checkpoint</a> (str regex=r&quot;model_\d+.pt&quot;)</td></tr>
<tr class="memdesc:ac2a05fd6065be94e8f17e6626f8badae"><td class="mdescLeft">&#160;</td><td class="mdescRight">Get the latest checkpoint file matching the regex.  <br /></td></tr>
<tr class="separator:ac2a05fd6065be94e8f17e6626f8badae"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af346001fffd195e37ff78eb7ffc73ac6"><td class="memItemLeft" align="right" valign="top">Callable&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface.html#af346001fffd195e37ff78eb7ffc73ac6">get_replay_buffer</a> (<a class="el" href="classrelab_1_1agents_1_1AgentInterface_1_1ReplayType.html">ReplayType</a> replay_type, float omega, float omega_is, int n_steps, float gamma=1.0)</td></tr>
<tr class="memdesc:af346001fffd195e37ff78eb7ffc73ac6"><td class="mdescLeft">&#160;</td><td class="mdescRight">Retrieve the constructor of the replay buffer requested as parameters.  <br /></td></tr>
<tr class="separator:af346001fffd195e37ff78eb7ffc73ac6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a704603931adc5148ee15311a72056935"><td class="memItemLeft" align="right" valign="top">Any&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface.html#a704603931adc5148ee15311a72056935">safe_load</a> (Checkpoint checkpoint, str key)</td></tr>
<tr class="memdesc:a704603931adc5148ee15311a72056935"><td class="mdescLeft">&#160;</td><td class="mdescRight">Load the value corresponding to the key in the checkpoint.  <br /></td></tr>
<tr class="separator:a704603931adc5148ee15311a72056935"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a74a42b5a97d74fb792cb43455d274a22"><td class="memItemLeft" align="right" valign="top">Optimizer&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface.html#a74a42b5a97d74fb792cb43455d274a22">safe_load_optimizer</a> (Checkpoint checkpoint, Union[Iterator[Parameter], List[Parameter]] params, float learning_rate, float adam_eps)</td></tr>
<tr class="memdesc:a74a42b5a97d74fb792cb43455d274a22"><td class="mdescLeft">&#160;</td><td class="mdescRight">Load the Adam optimizer from the checkpoint safely.  <br /></td></tr>
<tr class="separator:a74a42b5a97d74fb792cb43455d274a22"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pub-attribs" name="pub-attribs"></a>
Public Attributes</h2></td></tr>
<tr class="memitem:aebe9410ff0c783d702877cba754bdfe4"><td class="memItemLeft" align="right" valign="top"><a id="aebe9410ff0c783d702877cba754bdfe4" name="aebe9410ff0c783d702877cba754bdfe4"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>training</b></td></tr>
<tr class="memdesc:aebe9410ff0c783d702877cba754bdfe4"><td class="mdescLeft">&#160;</td><td class="mdescRight">Flag indicating whether the agent is in training mode. <br /></td></tr>
<tr class="separator:aebe9410ff0c783d702877cba754bdfe4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af9265d05f4810ac9f1e8a7b81fa2b3e4"><td class="memItemLeft" align="right" valign="top"><a id="af9265d05f4810ac9f1e8a7b81fa2b3e4" name="af9265d05f4810ac9f1e8a7b81fa2b3e4"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>device</b></td></tr>
<tr class="memdesc:af9265d05f4810ac9f1e8a7b81fa2b3e4"><td class="mdescLeft">&#160;</td><td class="mdescRight">The device (CPU/GPU) used for training computations. <br /></td></tr>
<tr class="separator:af9265d05f4810ac9f1e8a7b81fa2b3e4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2893cb65b44407a56a2063e76f46b084"><td class="memItemLeft" align="right" valign="top"><a id="a2893cb65b44407a56a2063e76f46b084" name="a2893cb65b44407a56a2063e76f46b084"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>max_queue_len</b></td></tr>
<tr class="memdesc:a2893cb65b44407a56a2063e76f46b084"><td class="mdescLeft">&#160;</td><td class="mdescRight">Maximum length for metric tracking queues (e.g., rewards, losses). <br /></td></tr>
<tr class="separator:a2893cb65b44407a56a2063e76f46b084"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a57c5cb4f2b2a27f6f493dc2cb35204de"><td class="memItemLeft" align="right" valign="top"><a id="a57c5cb4f2b2a27f6f493dc2cb35204de" name="a57c5cb4f2b2a27f6f493dc2cb35204de"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>current_step</b></td></tr>
<tr class="memdesc:a57c5cb4f2b2a27f6f493dc2cb35204de"><td class="mdescLeft">&#160;</td><td class="mdescRight">Counter tracking the number of training steps performed. <br /></td></tr>
<tr class="separator:a57c5cb4f2b2a27f6f493dc2cb35204de"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ada135459aeaa08b56654573f26d9d164"><td class="memItemLeft" align="right" valign="top"><a id="ada135459aeaa08b56654573f26d9d164" name="ada135459aeaa08b56654573f26d9d164"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>vfe_losses</b></td></tr>
<tr class="memdesc:ada135459aeaa08b56654573f26d9d164"><td class="mdescLeft">&#160;</td><td class="mdescRight">Queue containing the last variational free energy loss values. <br /></td></tr>
<tr class="separator:ada135459aeaa08b56654573f26d9d164"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4918c5297a7d20739113e60d376d54b0"><td class="memItemLeft" align="right" valign="top"><a id="a4918c5297a7d20739113e60d376d54b0" name="a4918c5297a7d20739113e60d376d54b0"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>betas</b></td></tr>
<tr class="memdesc:a4918c5297a7d20739113e60d376d54b0"><td class="mdescLeft">&#160;</td><td class="mdescRight">Queue containing the last beta values for variational inference. <br /></td></tr>
<tr class="separator:a4918c5297a7d20739113e60d376d54b0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a228b708b6845c61ae7fb1b263820e972"><td class="memItemLeft" align="right" valign="top"><a id="a228b708b6845c61ae7fb1b263820e972" name="a228b708b6845c61ae7fb1b263820e972"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>log_likelihoods</b></td></tr>
<tr class="memdesc:a228b708b6845c61ae7fb1b263820e972"><td class="mdescLeft">&#160;</td><td class="mdescRight">Queue containing the last log-likelihood values. <br /></td></tr>
<tr class="separator:a228b708b6845c61ae7fb1b263820e972"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a50846610d0bef5788babfada7b23bd7c"><td class="memItemLeft" align="right" valign="top"><a id="a50846610d0bef5788babfada7b23bd7c" name="a50846610d0bef5788babfada7b23bd7c"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>kl_divergences</b></td></tr>
<tr class="memdesc:a50846610d0bef5788babfada7b23bd7c"><td class="mdescLeft">&#160;</td><td class="mdescRight">Queue containing the last KL-divergence values. <br /></td></tr>
<tr class="separator:a50846610d0bef5788babfada7b23bd7c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afd45587d464b4589f99dffc60c91c86d"><td class="memItemLeft" align="right" valign="top"><a id="afd45587d464b4589f99dffc60c91c86d" name="afd45587d464b4589f99dffc60c91c86d"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>process</b></td></tr>
<tr class="memdesc:afd45587d464b4589f99dffc60c91c86d"><td class="mdescLeft">&#160;</td><td class="mdescRight">Object representing the current process, used to track memory usage. <br /></td></tr>
<tr class="separator:afd45587d464b4589f99dffc60c91c86d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a01dbb8f53af242be4950b87001457051"><td class="memItemLeft" align="right" valign="top"><a id="a01dbb8f53af242be4950b87001457051" name="a01dbb8f53af242be4950b87001457051"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>virtual_memory</b></td></tr>
<tr class="memdesc:a01dbb8f53af242be4950b87001457051"><td class="mdescLeft">&#160;</td><td class="mdescRight">Queue tracking virtual memory usage over time. <br /></td></tr>
<tr class="separator:a01dbb8f53af242be4950b87001457051"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afc8a86652d557c030960e658bcffc7bf"><td class="memItemLeft" align="right" valign="top"><a id="afc8a86652d557c030960e658bcffc7bf" name="afc8a86652d557c030960e658bcffc7bf"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>residential_memory</b></td></tr>
<tr class="memdesc:afc8a86652d557c030960e658bcffc7bf"><td class="mdescLeft">&#160;</td><td class="mdescRight">Queue tracking residential memory usage over time. <br /></td></tr>
<tr class="separator:afc8a86652d557c030960e658bcffc7bf"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5391a5dc70168153d9f2870c77c08817"><td class="memItemLeft" align="right" valign="top"><a id="a5391a5dc70168153d9f2870c77c08817" name="a5391a5dc70168153d9f2870c77c08817"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>episodic_rewards</b></td></tr>
<tr class="memdesc:a5391a5dc70168153d9f2870c77c08817"><td class="mdescLeft">&#160;</td><td class="mdescRight">Queue containing the last episodic reward values. <br /></td></tr>
<tr class="separator:a5391a5dc70168153d9f2870c77c08817"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab4a9667415d86d25f96a2b24192df7b0"><td class="memItemLeft" align="right" valign="top"><a id="ab4a9667415d86d25f96a2b24192df7b0" name="ab4a9667415d86d25f96a2b24192df7b0"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>current_episodic_reward</b></td></tr>
<tr class="memdesc:ab4a9667415d86d25f96a2b24192df7b0"><td class="mdescLeft">&#160;</td><td class="mdescRight">Accumulator for the current episode's reward. <br /></td></tr>
<tr class="separator:ab4a9667415d86d25f96a2b24192df7b0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:add513abea2b924b9ff01ea780e615226"><td class="memItemLeft" align="right" valign="top"><a id="add513abea2b924b9ff01ea780e615226" name="add513abea2b924b9ff01ea780e615226"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>time_elapsed</b></td></tr>
<tr class="memdesc:add513abea2b924b9ff01ea780e615226"><td class="mdescLeft">&#160;</td><td class="mdescRight">Queue containing the time elapsed between consecutive training iterations. <br /></td></tr>
<tr class="separator:add513abea2b924b9ff01ea780e615226"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3946d85e422e39dfb53bdcf0bdb157e2"><td class="memItemLeft" align="right" valign="top"><a id="a3946d85e422e39dfb53bdcf0bdb157e2" name="a3946d85e422e39dfb53bdcf0bdb157e2"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>last_time</b></td></tr>
<tr class="memdesc:a3946d85e422e39dfb53bdcf0bdb157e2"><td class="mdescLeft">&#160;</td><td class="mdescRight">Timestamp of the last training iteration. <br /></td></tr>
<tr class="separator:a3946d85e422e39dfb53bdcf0bdb157e2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab9e85b5ccd071a9bd1b31108af768b7f"><td class="memItemLeft" align="right" valign="top"><a id="ab9e85b5ccd071a9bd1b31108af768b7f" name="ab9e85b5ccd071a9bd1b31108af768b7f"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>episode_lengths</b></td></tr>
<tr class="memdesc:ab9e85b5ccd071a9bd1b31108af768b7f"><td class="mdescLeft">&#160;</td><td class="mdescRight">Queue containing the lengths of recent episodes. <br /></td></tr>
<tr class="separator:ab9e85b5ccd071a9bd1b31108af768b7f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a57c7c72ae83d068259e19c2546fd7db9"><td class="memItemLeft" align="right" valign="top"><a id="a57c7c72ae83d068259e19c2546fd7db9" name="a57c7c72ae83d068259e19c2546fd7db9"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>current_episode_length</b></td></tr>
<tr class="memdesc:a57c7c72ae83d068259e19c2546fd7db9"><td class="mdescLeft">&#160;</td><td class="mdescRight">Counter for the current episode's length. <br /></td></tr>
<tr class="separator:a57c7c72ae83d068259e19c2546fd7db9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7ee2c0fa4c30526206bd7d02cfe321ce"><td class="memItemLeft" align="right" valign="top"><a id="a7ee2c0fa4c30526206bd7d02cfe321ce" name="a7ee2c0fa4c30526206bd7d02cfe321ce"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>writer</b></td></tr>
<tr class="memdesc:a7ee2c0fa4c30526206bd7d02cfe321ce"><td class="mdescLeft">&#160;</td><td class="mdescRight">TensorBoard summary writer for logging training metrics. <br /></td></tr>
<tr class="separator:a7ee2c0fa4c30526206bd7d02cfe321ce"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><p>The interface that all agents must implement. </p>
</div><h2 class="groupheader">Constructor &amp; Destructor Documentation</h2>
<a id="a37b65628d214627afae8cf7c8f576435" name="a37b65628d214627afae8cf7c8f576435"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a37b65628d214627afae8cf7c8f576435">&#9670;&#160;</a></span>__init__()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> None relab.agents.AgentInterface.AgentInterface.__init__ </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>training</em> = <code>True</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Create an agent. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">training</td><td>True if the agent is being training, False otherwise </td></tr>
  </table>
  </dd>
</dl>

<p>Reimplemented in <a class="el" href="classrelab_1_1agents_1_1QRDQN_1_1QRDQN.html#aac3f9b94fe8b45ea63035c42ebdca214">relab.agents.QRDQN.QRDQN</a>, <a class="el" href="classrelab_1_1agents_1_1RainbowIQN_1_1RainbowIQN.html#a3262211e23dc1181ae30580740beb2b9">relab.agents.RainbowIQN.RainbowIQN</a>, <a class="el" href="classrelab_1_1agents_1_1IQN_1_1IQN.html#a744f1a08268e137f79f3e6e6baafa32d">relab.agents.IQN.IQN</a>, <a class="el" href="classrelab_1_1agents_1_1PrioritizedMDQN_1_1PrioritizedMDQN.html#a1d880f1cfffb16b9e29d87fe39e753c2">relab.agents.PrioritizedMDQN.PrioritizedMDQN</a>, <a class="el" href="classrelab_1_1agents_1_1MDQN_1_1MDQN.html#a8a4b112cc8177e91233bd1c5d090e008">relab.agents.MDQN.MDQN</a>, <a class="el" href="classrelab_1_1agents_1_1NoisyCDQN_1_1NoisyCDQN.html#a6958dcd69e1a355c07f7f85c23362338">relab.agents.NoisyCDQN.NoisyCDQN</a>, <a class="el" href="classrelab_1_1agents_1_1CDQN_1_1CDQN.html#a4bb9953c5b41bfaaa97b121424775214">relab.agents.CDQN.CDQN</a>, <a class="el" href="classrelab_1_1agents_1_1DDQN_1_1DDQN.html#a78152f0e1c6a5e5f1d0eda5fb92c37e0">relab.agents.DDQN.DDQN</a>, <a class="el" href="classrelab_1_1agents_1_1DuelingDDQN_1_1DuelingDDQN.html#a4cd4c3c9daf4a504ae725e9b68ed04fe">relab.agents.DuelingDDQN.DuelingDDQN</a>, <a class="el" href="classrelab_1_1agents_1_1NoisyDDQN_1_1NoisyDDQN.html#a13fbd3d92d5641d5a454974c0894cbec">relab.agents.NoisyDDQN.NoisyDDQN</a>, <a class="el" href="classrelab_1_1agents_1_1DuelingDQN_1_1DuelingDQN.html#ab8ca0aa540e382510474fc852fa88993">relab.agents.DuelingDQN.DuelingDQN</a>, <a class="el" href="classrelab_1_1agents_1_1NoisyDQN_1_1NoisyDQN.html#ad7e902ae7cf4bbf5bb69df947be940f0">relab.agents.NoisyDQN.NoisyDQN</a>, <a class="el" href="classrelab_1_1agents_1_1DQN_1_1DQN.html#a2d91aced72b5b4b01098fba9e85abaf3">relab.agents.DQN.DQN</a>, <a class="el" href="classrelab_1_1agents_1_1RainbowDQN_1_1RainbowDQN.html#a2b2d06a182d120ed06ea1bc7b2ddb3e3">relab.agents.RainbowDQN.RainbowDQN</a>, <a class="el" href="classrelab_1_1agents_1_1PrioritizedDDQN_1_1PrioritizedDDQN.html#a0ee8d33986b8ee610e32e8f81e5f52e6">relab.agents.PrioritizedDDQN.PrioritizedDDQN</a>, <a class="el" href="classrelab_1_1agents_1_1PrioritizedDQN_1_1PrioritizedDQN.html#a4b0ec0729b782e8673397337d6c4cbda">relab.agents.PrioritizedDQN.PrioritizedDQN</a>, <a class="el" href="classrelab_1_1agents_1_1VariationalModel_1_1VariationalModel.html#a93d9be88fe526e4f87df64038e057bf0">relab.agents.VariationalModel.VariationalModel</a>, <a class="el" href="classrelab_1_1agents_1_1DiscreteVAE_1_1DiscreteVAE.html#aaebdadea8b288ebecb23b7949698d30f">relab.agents.DiscreteVAE.DiscreteVAE</a>, <a class="el" href="classrelab_1_1agents_1_1JointVAE_1_1JointVAE.html#adffd21ab899dff4038ed70b9470a454b">relab.agents.JointVAE.JointVAE</a>, <a class="el" href="classrelab_1_1agents_1_1BetaHMM_1_1BetaHMM.html#a807f36105830e4407464bb07e5b59a13">relab.agents.BetaHMM.BetaHMM</a>, <a class="el" href="classrelab_1_1agents_1_1HMM_1_1HMM.html#a07357b8023e9dc1365ebbc17f3dd71fd">relab.agents.HMM.HMM</a>, <a class="el" href="classrelab_1_1agents_1_1BetaVAE_1_1BetaVAE.html#a0a216417721391d30d227c1428f640b6">relab.agents.BetaVAE.BetaVAE</a>, <a class="el" href="classrelab_1_1agents_1_1VAE_1_1VAE.html#ae8bb960bf9335d927d4dda558e5fb8c0">relab.agents.VAE.VAE</a>, <a class="el" href="classrelab_1_1agents_1_1DiscreteHMM_1_1DiscreteHMM.html#ad7e5d40760d4d8867011dacf14b34a59">relab.agents.DiscreteHMM.DiscreteHMM</a>, <a class="el" href="classrelab_1_1agents_1_1JointHMM_1_1JointHMM.html#a6b0348283428396d61b55b41014c5d10">relab.agents.JointHMM.JointHMM</a>, and <a class="el" href="classrelab_1_1agents_1_1Random_1_1Random.html#a73d98794f727597e7d8d3450611e6deb">relab.agents.Random.Random</a>.</p>

</div>
</div>
<h2 class="groupheader">Member Function Documentation</h2>
<a id="a4725a741348861a5c9f9395df508f063" name="a4725a741348861a5c9f9395df508f063"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4725a741348861a5c9f9395df508f063">&#9670;&#160;</a></span>as_dict()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def relab.agents.AgentInterface.AgentInterface.as_dict </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">"
Convert the agent into a dictionary that can be saved on the filesystem.
@return the dictionary
</pre> 
<p>Reimplemented in <a class="el" href="classrelab_1_1agents_1_1DQN_1_1DQN.html#afaea756d733758ffbba110e0ebea7cdf">relab.agents.DQN.DQN</a>, <a class="el" href="classrelab_1_1agents_1_1HMM_1_1HMM.html#a7d1f79d47676a11371d3fd783cf83261">relab.agents.HMM.HMM</a>, <a class="el" href="classrelab_1_1agents_1_1Random_1_1Random.html#a4145c69de551eca4ec85043c42593034">relab.agents.Random.Random</a>, <a class="el" href="classrelab_1_1agents_1_1VAE_1_1VAE.html#ab96439995ec822fe93ab5a535bf456da">relab.agents.VAE.VAE</a>, and <a class="el" href="classrelab_1_1agents_1_1VariationalModel_1_1VariationalModel.html#a0cfef604048daab9f54bde2346043be3">relab.agents.VariationalModel.VariationalModel</a>.</p>

</div>
</div>
<a id="a5766245d893fd33acda1bb041e6a5173" name="a5766245d893fd33acda1bb041e6a5173"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5766245d893fd33acda1bb041e6a5173">&#9670;&#160;</a></span>demo()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> None relab.agents.AgentInterface.AgentInterface.demo </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Env&#160;</td>
          <td class="paramname"><em>env</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">str&#160;</td>
          <td class="paramname"><em>gif_name</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int &#160;</td>
          <td class="paramname"><em>max_frames</em> = <code>10000</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Demonstrate the agent policy in the gym environment passed as parameters. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">env</td><td>the gym environment </td></tr>
    <tr><td class="paramname">gif_name</td><td>the name of the GIF file in which to save the demo </td></tr>
    <tr><td class="paramname">max_frames</td><td>the maximum number of frames to include in the GIF file </td></tr>
  </table>
  </dd>
</dl>

<p>Reimplemented in <a class="el" href="classrelab_1_1agents_1_1VariationalModel_1_1VariationalModel.html#a8379bf52ee30929b04024faff9c3b529">relab.agents.VariationalModel.VariationalModel</a>.</p>

</div>
</div>
<a id="ac2a05fd6065be94e8f17e6626f8badae" name="ac2a05fd6065be94e8f17e6626f8badae"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac2a05fd6065be94e8f17e6626f8badae">&#9670;&#160;</a></span>get_latest_checkpoint()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"> Optional[str] relab.agents.AgentInterface.AgentInterface.get_latest_checkpoint </td>
          <td>(</td>
          <td class="paramtype">str &#160;</td>
          <td class="paramname"><em>regex</em> = <code>r&quot;model_\d+.pt&quot;</code></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Get the latest checkpoint file matching the regex. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">regex</td><td>the regex checking whether a file name is a valid checkpoint file </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>None if an error occurred, else the path to the latest checkpoint </dd></dl>

</div>
</div>
<a id="af346001fffd195e37ff78eb7ffc73ac6" name="af346001fffd195e37ff78eb7ffc73ac6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af346001fffd195e37ff78eb7ffc73ac6">&#9670;&#160;</a></span>get_replay_buffer()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"> Callable relab.agents.AgentInterface.AgentInterface.get_replay_buffer </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classrelab_1_1agents_1_1AgentInterface_1_1ReplayType.html">ReplayType</a>&#160;</td>
          <td class="paramname"><em>replay_type</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float&#160;</td>
          <td class="paramname"><em>omega</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float&#160;</td>
          <td class="paramname"><em>omega_is</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>n_steps</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float &#160;</td>
          <td class="paramname"><em>gamma</em> = <code>1.0</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Retrieve the constructor of the replay buffer requested as parameters. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">replay_type</td><td>the type of replay buffer </td></tr>
    <tr><td class="paramname">omega</td><td>the prioritization exponent </td></tr>
    <tr><td class="paramname">omega_is</td><td>the important sampling exponent </td></tr>
    <tr><td class="paramname">n_steps</td><td>the number of steps for which rewards are accumulated in multistep Q-learning </td></tr>
    <tr><td class="paramname">gamma</td><td>the discount factor </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>the constructor of the replay buffer </dd></dl>

</div>
</div>
<a id="a162eb28fb9a698f2a58908c4a1d6110e" name="a162eb28fb9a698f2a58908c4a1d6110e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a162eb28fb9a698f2a58908c4a1d6110e">&#9670;&#160;</a></span>load()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> Tuple[str, Checkpoint] relab.agents.AgentInterface.AgentInterface.load </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Optional[str] &#160;</td>
          <td class="paramname"><em>checkpoint_name</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Optional[str] &#160;</td>
          <td class="paramname"><em>buffer_checkpoint_name</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Load an agent from the filesystem. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">checkpoint_name</td><td>the name of the agent checkpoint to load </td></tr>
    <tr><td class="paramname">buffer_checkpoint_name</td><td>the name of the replay buffer checkpoint to load (None for default name) </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>a tuple containing the checkpoint path and the checkpoint object </dd></dl>

<p>Reimplemented in <a class="el" href="classrelab_1_1agents_1_1DQN_1_1DQN.html#ab5eba6790ccbd1d07171f0c2a5df2f93">relab.agents.DQN.DQN</a>, <a class="el" href="classrelab_1_1agents_1_1HMM_1_1HMM.html#ae8c30797463eff241e04240b865b1acc">relab.agents.HMM.HMM</a>, <a class="el" href="classrelab_1_1agents_1_1Random_1_1Random.html#a07910912fc17ebc851653cf54f87aac5">relab.agents.Random.Random</a>, <a class="el" href="classrelab_1_1agents_1_1VAE_1_1VAE.html#a12781086578c355fef79b0cf676392d8">relab.agents.VAE.VAE</a>, and <a class="el" href="classrelab_1_1agents_1_1VariationalModel_1_1VariationalModel.html#a341f759b14b0148b5db8fad14774d1ad">relab.agents.VariationalModel.VariationalModel</a>.</p>

</div>
</div>
<a id="a92338de60d467d97e4c1939844b8533b" name="a92338de60d467d97e4c1939844b8533b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a92338de60d467d97e4c1939844b8533b">&#9670;&#160;</a></span>log_performance_in_tensorboard()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> None relab.agents.AgentInterface.AgentInterface.log_performance_in_tensorboard </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Log the agent performance in tensorboard, if the internal queue. </p>

</div>
</div>
<a id="af4ab3f64e484947cb12ce99df56d9e4a" name="af4ab3f64e484947cb12ce99df56d9e4a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af4ab3f64e484947cb12ce99df56d9e4a">&#9670;&#160;</a></span>report()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> None relab.agents.AgentInterface.AgentInterface.report </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">SupportsFloat&#160;</td>
          <td class="paramname"><em>reward</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>done</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Dict[str, Any] &#160;</td>
          <td class="paramname"><em>model_losses</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Keep track of the last episodic rewards, episode length, and time elapse since last training iteration. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">reward</td><td>the current reward </td></tr>
    <tr><td class="paramname">done</td><td>whether the episode ended </td></tr>
    <tr><td class="paramname">model_losses</td><td>the current variational free energy, log-likelihood and KL-divergence </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a704603931adc5148ee15311a72056935" name="a704603931adc5148ee15311a72056935"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a704603931adc5148ee15311a72056935">&#9670;&#160;</a></span>safe_load()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"> Any relab.agents.AgentInterface.AgentInterface.safe_load </td>
          <td>(</td>
          <td class="paramtype">Checkpoint&#160;</td>
          <td class="paramname"><em>checkpoint</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">str&#160;</td>
          <td class="paramname"><em>key</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Load the value corresponding to the key in the checkpoint. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">checkpoint</td><td>the checkpoint </td></tr>
    <tr><td class="paramname">key</td><td>the key </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>the value, or None if the key is not in the checkpoint </dd></dl>

</div>
</div>
<a id="a74a42b5a97d74fb792cb43455d274a22" name="a74a42b5a97d74fb792cb43455d274a22"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a74a42b5a97d74fb792cb43455d274a22">&#9670;&#160;</a></span>safe_load_optimizer()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"> Optimizer relab.agents.AgentInterface.AgentInterface.safe_load_optimizer </td>
          <td>(</td>
          <td class="paramtype">Checkpoint&#160;</td>
          <td class="paramname"><em>checkpoint</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Union[Iterator[Parameter], List[Parameter]]&#160;</td>
          <td class="paramname"><em>params</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float&#160;</td>
          <td class="paramname"><em>learning_rate</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float
    &#160;</td>
          <td class="paramname"><em>adam_eps</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Load the Adam optimizer from the checkpoint safely. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">checkpoint</td><td>the checkpoint </td></tr>
    <tr><td class="paramname">params</td><td>the parameters that the Adam optimizer must optimize </td></tr>
    <tr><td class="paramname">learning_rate</td><td>the learning rate </td></tr>
    <tr><td class="paramname">adam_eps</td><td>the epsilon parameter of the Adam optimizer </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>the loaded Adam optimizer </dd></dl>

</div>
</div>
<a id="a19be8462f89a85eb5c6f4dc9c07201f9" name="a19be8462f89a85eb5c6f4dc9c07201f9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a19be8462f89a85eb5c6f4dc9c07201f9">&#9670;&#160;</a></span>save()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> None relab.agents.AgentInterface.AgentInterface.save </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">str&#160;</td>
          <td class="paramname"><em>checkpoint_name</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Optional[str] &#160;</td>
          <td class="paramname"><em>buffer_checkpoint_name</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Save the agent on the filesystem. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">checkpoint_name</td><td>the name of the checkpoint in which to save the agent </td></tr>
    <tr><td class="paramname">buffer_checkpoint_name</td><td>the name of the checkpoint to save the replay buffer (None for default name) </td></tr>
  </table>
  </dd>
</dl>

<p>Reimplemented in <a class="el" href="classrelab_1_1agents_1_1DQN_1_1DQN.html#a90e9b39f00d5c50fcdb6b506c9fd99fd">relab.agents.DQN.DQN</a>, <a class="el" href="classrelab_1_1agents_1_1HMM_1_1HMM.html#afdee3f46edc59ec5251d629b2b143a9c">relab.agents.HMM.HMM</a>, <a class="el" href="classrelab_1_1agents_1_1Random_1_1Random.html#a8ef8a53396d96ee6e0c119aacafb3d21">relab.agents.Random.Random</a>, and <a class="el" href="classrelab_1_1agents_1_1VAE_1_1VAE.html#a7aa572266f8a26592adc87ddd656d9a7">relab.agents.VAE.VAE</a>.</p>

</div>
</div>
<a id="a5dc04ff5e1441ba6216f2f24e8d8c632" name="a5dc04ff5e1441ba6216f2f24e8d8c632"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5dc04ff5e1441ba6216f2f24e8d8c632">&#9670;&#160;</a></span>step()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> ActionType relab.agents.AgentInterface.AgentInterface.step </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">ObservationType&#160;</td>
          <td class="paramname"><em>obs</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Select the next action to perform in the environment. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">obs</td><td>the observation available to make the decision </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>the next action to perform </dd></dl>

<p>Reimplemented in <a class="el" href="classrelab_1_1agents_1_1DQN_1_1DQN.html#a84fd3832544a0135720516681e4fff3b">relab.agents.DQN.DQN</a>, <a class="el" href="classrelab_1_1agents_1_1Random_1_1Random.html#ae805ddead68cb2fe9f8e795d0ac0bb39">relab.agents.Random.Random</a>, and <a class="el" href="classrelab_1_1agents_1_1VariationalModel_1_1VariationalModel.html#aa26c035b6ded8bc45892e7efa69e35f6">relab.agents.VariationalModel.VariationalModel</a>.</p>

</div>
</div>
<a id="acb6aee67e6278cd5230ab2808f774577" name="acb6aee67e6278cd5230ab2808f774577"></a>
<h2 class="memtitle"><span class="permalink"><a href="#acb6aee67e6278cd5230ab2808f774577">&#9670;&#160;</a></span>train()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> None relab.agents.AgentInterface.AgentInterface.train </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Env&#160;</td>
          <td class="paramname"><em>env</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Train the agent in the gym environment passed as parameters. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">env</td><td>the gym environment </td></tr>
  </table>
  </dd>
</dl>

<p>Reimplemented in <a class="el" href="classrelab_1_1agents_1_1DQN_1_1DQN.html#afb3c1f57ed16d94b8cd82bf4ffe24276">relab.agents.DQN.DQN</a>, <a class="el" href="classrelab_1_1agents_1_1Random_1_1Random.html#a3b25a43a7232d592d591740723b70e2b">relab.agents.Random.Random</a>, and <a class="el" href="classrelab_1_1agents_1_1VariationalModel_1_1VariationalModel.html#a589072db333009b5045584060a57dc17">relab.agents.VariationalModel.VariationalModel</a>.</p>

</div>
</div>
<hr/>The documentation for this class was generated from the following file:<ul>
<li>relab/agents/AgentInterface.py</li>
</ul>
</div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><b>relab</b></li><li class="navelem"><b>agents</b></li><li class="navelem"><b>AgentInterface</b></li><li class="navelem"><a class="el" href="classrelab_1_1agents_1_1AgentInterface_1_1AgentInterface.html">AgentInterface</a></li>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.6 </li>
  </ul>
</div>
</body>
</html>
